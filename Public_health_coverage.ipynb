{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T18:24:04.808469Z",
     "start_time": "2024-09-04T18:24:04.805573Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 15:28:29.784287: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-21 15:28:29.985562: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-21 15:28:29.985584: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-21 15:28:29.986705: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-21 15:28:30.100400: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-21 15:28:30.101726: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-21 15:28:30.971937: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.src.metrics import accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbedb99c26675407",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T18:24:04.831157Z",
     "start_time": "2024-09-04T18:24:04.827183Z"
    }
   },
   "outputs": [],
   "source": [
    "from folktables import ACSDataSource, ACSPublicCoverage\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7409ae407a777f46",
   "metadata": {},
   "source": [
    "# Load Data for All US States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d3bb97f57612c07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T18:24:39.365213Z",
     "start_time": "2024-09-04T18:24:04.864792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AL (18525, 19) (18525,) (18525,)\n",
      "AK (2377, 19) (2377,) (2377,)\n",
      "AZ (24988, 19) (24988,) (24988,)\n",
      "AR (11838, 19) (11838,) (11838,)\n",
      "CA (138554, 19) (138554,) (138554,)\n",
      "CO (17630, 19) (17630,) (17630,)\n",
      "CT (11204, 19) (11204,) (11204,)\n",
      "DE (2871, 19) (2871,) (2871,)\n",
      "FL (71297, 19) (71297,) (71297,)\n",
      "GA (37701, 19) (37701,) (37701,)\n",
      "HI (4660, 19) (4660,) (4660,)\n",
      "ID (5937, 19) (5937,) (5937,)\n",
      "IL (42827, 19) (42827,) (42827,)\n",
      "IN (24330, 19) (24330,) (24330,)\n",
      "IA (10241, 19) (10241,) (10241,)\n",
      "KS (10242, 19) (10242,) (10242,)\n",
      "KY (17166, 19) (17166,) (17166,)\n",
      "LA (16879, 19) (16879,) (16879,)\n",
      "ME (4513, 19) (4513,) (4513,)\n",
      "MD (18025, 19) (18025,) (18025,)\n",
      "MA (21992, 19) (21992,) (21992,)\n",
      "MI (35624, 19) (35624,) (35624,)\n",
      "MN (16357, 19) (16357,) (16357,)\n",
      "MS (11831, 19) (11831,) (11831,)\n",
      "MO (22327, 19) (22327,) (22327,)\n",
      "MT (3519, 19) (3519,) (3519,)\n",
      "NE (6332, 19) (6332,) (6332,)\n",
      "NV (10201, 19) (10201,) (10201,)\n",
      "NH (4251, 19) (4251,) (4251,)\n",
      "NJ (27609, 19) (27609,) (27609,)\n",
      "NM (7693, 19) (7693,) (7693,)\n",
      "NY (67551, 19) (67551,) (67551,)\n",
      "NC (37181, 19) (37181,) (37181,)\n",
      "ND (2263, 19) (2263,) (2263,)\n",
      "OH (41191, 19) (41191,) (41191,)\n",
      "OK (14851, 19) (14851,) (14851,)\n",
      "OR (14252, 19) (14252,) (14252,)\n",
      "PA (44081, 19) (44081,) (44081,)\n",
      "RI (3325, 19) (3325,) (3325,)\n",
      "SC (18693, 19) (18693,) (18693,)\n",
      "SD (2852, 19) (2852,) (2852,)\n",
      "TN (25497, 19) (25497,) (25497,)\n",
      "TX (98928, 19) (98928,) (98928,)\n",
      "UT (11584, 19) (11584,) (11584,)\n",
      "VT (2069, 19) (2069,) (2069,)\n",
      "VA (27518, 19) (27518,) (27518,)\n",
      "WA (24312, 19) (24312,) (24312,)\n",
      "WV (7136, 19) (7136,) (7136,)\n",
      "WI (18653, 19) (18653,) (18653,)\n",
      "WY (1896, 19) (1896,) (1896,)\n"
     ]
    }
   ],
   "source": [
    "# List of all 50 US state abbreviations\n",
    "states = [\n",
    "    \"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\",\n",
    "    \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\",\n",
    "    \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\",\n",
    "    \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\",\n",
    "    \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"\n",
    "]\n",
    "\n",
    "# Dictionary to store data, features, and labels for each state\n",
    "state_data = {}\n",
    "state_features = {}\n",
    "state_labels = {}\n",
    "state_groups = {}\n",
    "\n",
    "# Assuming `data_source` and `ACSIncome` are already defined\n",
    "for state in states:\n",
    "    # Load data for each state\n",
    "    state_data[state] = data_source.get_data(states=[state], download=True)\n",
    "    # Convert to features and labels\n",
    "    state_features[state], state_labels[state], state_groups[state]= ACSPublicCoverage.df_to_numpy(state_data[state])\n",
    "    state_features[state] = scaler.fit_transform(state_features[state])\n",
    "    state_groups[state] = np.where(state_groups[state] == 1, 0, 1)\n",
    "    print(state, state_features[state].shape, state_labels[state].shape,state_groups[state].shape)\n",
    "\n",
    "# Example usage: Access data, features, and labels for California (CA)\n",
    "ca_features = state_features[\"CA\"]\n",
    "ca_labels = state_labels[\"CA\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ecfcc057d93c0",
   "metadata": {},
   "source": [
    "# Split Data into Train, Validation, and Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "105236c0fa9e4b79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T18:24:39.548044Z",
     "start_time": "2024-09-04T18:24:39.396463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AL: Train: (9262, 19), Val: (5557, 19), Test: (3706, 19)\n",
      "AK: Train: (1188, 19), Val: (713, 19), Test: (476, 19)\n",
      "AZ: Train: (12494, 19), Val: (7496, 19), Test: (4998, 19)\n",
      "AR: Train: (5919, 19), Val: (3551, 19), Test: (2368, 19)\n",
      "CA: Train: (69277, 19), Val: (41566, 19), Test: (27711, 19)\n",
      "CO: Train: (8815, 19), Val: (5289, 19), Test: (3526, 19)\n",
      "CT: Train: (5602, 19), Val: (3361, 19), Test: (2241, 19)\n",
      "DE: Train: (1435, 19), Val: (861, 19), Test: (575, 19)\n",
      "FL: Train: (35648, 19), Val: (21389, 19), Test: (14260, 19)\n",
      "GA: Train: (18850, 19), Val: (11310, 19), Test: (7541, 19)\n",
      "HI: Train: (2330, 19), Val: (1398, 19), Test: (932, 19)\n",
      "ID: Train: (2968, 19), Val: (1781, 19), Test: (1188, 19)\n",
      "IL: Train: (21413, 19), Val: (12848, 19), Test: (8566, 19)\n",
      "IN: Train: (12165, 19), Val: (7299, 19), Test: (4866, 19)\n",
      "IA: Train: (5120, 19), Val: (3072, 19), Test: (2049, 19)\n",
      "KS: Train: (5121, 19), Val: (3072, 19), Test: (2049, 19)\n",
      "KY: Train: (8583, 19), Val: (5149, 19), Test: (3434, 19)\n",
      "LA: Train: (8439, 19), Val: (5064, 19), Test: (3376, 19)\n",
      "ME: Train: (2256, 19), Val: (1354, 19), Test: (903, 19)\n",
      "MD: Train: (9012, 19), Val: (5407, 19), Test: (3606, 19)\n",
      "MA: Train: (10996, 19), Val: (6597, 19), Test: (4399, 19)\n",
      "MI: Train: (17812, 19), Val: (10687, 19), Test: (7125, 19)\n",
      "MN: Train: (8178, 19), Val: (4907, 19), Test: (3272, 19)\n",
      "MS: Train: (5915, 19), Val: (3549, 19), Test: (2367, 19)\n",
      "MO: Train: (11163, 19), Val: (6698, 19), Test: (4466, 19)\n",
      "MT: Train: (1759, 19), Val: (1056, 19), Test: (704, 19)\n",
      "NE: Train: (3166, 19), Val: (1899, 19), Test: (1267, 19)\n",
      "NV: Train: (5100, 19), Val: (3060, 19), Test: (2041, 19)\n",
      "NH: Train: (2125, 19), Val: (1275, 19), Test: (851, 19)\n",
      "NJ: Train: (13804, 19), Val: (8283, 19), Test: (5522, 19)\n",
      "NM: Train: (3846, 19), Val: (2308, 19), Test: (1539, 19)\n",
      "NY: Train: (33775, 19), Val: (20265, 19), Test: (13511, 19)\n",
      "NC: Train: (18590, 19), Val: (11154, 19), Test: (7437, 19)\n",
      "ND: Train: (1131, 19), Val: (679, 19), Test: (453, 19)\n",
      "OH: Train: (20595, 19), Val: (12357, 19), Test: (8239, 19)\n",
      "OK: Train: (7425, 19), Val: (4455, 19), Test: (2971, 19)\n",
      "OR: Train: (7126, 19), Val: (4275, 19), Test: (2851, 19)\n",
      "PA: Train: (22040, 19), Val: (13224, 19), Test: (8817, 19)\n",
      "RI: Train: (1662, 19), Val: (997, 19), Test: (666, 19)\n",
      "SC: Train: (9346, 19), Val: (5608, 19), Test: (3739, 19)\n",
      "SD: Train: (1426, 19), Val: (855, 19), Test: (571, 19)\n",
      "TN: Train: (12748, 19), Val: (7649, 19), Test: (5100, 19)\n",
      "TX: Train: (49464, 19), Val: (29678, 19), Test: (19786, 19)\n",
      "UT: Train: (5792, 19), Val: (3475, 19), Test: (2317, 19)\n",
      "VT: Train: (1034, 19), Val: (621, 19), Test: (414, 19)\n",
      "VA: Train: (13759, 19), Val: (8255, 19), Test: (5504, 19)\n",
      "WA: Train: (12156, 19), Val: (7293, 19), Test: (4863, 19)\n",
      "WV: Train: (3568, 19), Val: (2140, 19), Test: (1428, 19)\n",
      "WI: Train: (9326, 19), Val: (5596, 19), Test: (3731, 19)\n",
      "WY: Train: (948, 19), Val: (568, 19), Test: (380, 19)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Define dictionaries to store train, validation, and test data for each state\n",
    "train_features = {}\n",
    "train_labels = {}\n",
    "train_groups = {}\n",
    "val_features = {}\n",
    "val_labels = {}\n",
    "vali_groups = {}\n",
    "test_features = {}\n",
    "test_labels = {}\n",
    "test_groups = {}\n",
    "all_test_features = []\n",
    "all_test_labels = []\n",
    "all_test_groups = []\n",
    "all_vaild_features = []\n",
    "all_valid_labels = []\n",
    "all_valid_groups = []\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Split ratio configuration\n",
    "train_ratio = 0.5\n",
    "val_ratio = 0.3\n",
    "test_ratio = 0.2\n",
    "\n",
    "for state in states:\n",
    "    # Get the features and labels for the state\n",
    "    features = state_features[state]\n",
    "    labels = state_labels[state]\n",
    "    groups = state_groups[state]\n",
    "\n",
    "    # First split into train and temp (validation + test) sets\n",
    "    X_train, X_temp, y_train, y_temp, s_train, s_temp = train_test_split(\n",
    "        features, labels, groups, test_size=(1 - train_ratio), random_state=42)\n",
    "\n",
    "    # Then split the temp set into validation and test sets\n",
    "    X_val, X_test, y_val, y_test, s_val, s_test = train_test_split(\n",
    "        X_temp, y_temp, s_temp, test_size=(test_ratio / (val_ratio + test_ratio)), random_state=42)\n",
    "\n",
    "    # Store the splits into respective dictionaries\n",
    "    train_features[state] = X_train\n",
    "    train_labels[state] = y_train\n",
    "    train_groups[state] = s_train\n",
    "    val_features[state] = X_val\n",
    "    val_labels[state] = y_val\n",
    "    vali_groups[state] = s_val\n",
    "    test_features[state] = X_test\n",
    "    test_labels[state] = y_test\n",
    "    test_groups[state] = s_test\n",
    "    all_vaild_features.append(X_val)\n",
    "    all_valid_labels.append(y_val)\n",
    "    all_valid_groups.append(s_val)\n",
    "    all_test_features.append(X_test)\n",
    "    all_test_labels.append(y_test)\n",
    "    all_test_groups.append(s_test)\n",
    "\n",
    "    # Print the shapes for verification\n",
    "    print(f\"{state}: Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n",
    "all_test_features = np.concatenate(all_test_features)\n",
    "all_test_labels = np.concatenate(all_test_labels)\n",
    "all_test_groups = np.concatenate(all_test_groups)\n",
    "all_vaild_features=np.concatenate(all_vaild_features)\n",
    "all_vaild_labels=np.concatenate(all_valid_labels)\n",
    "all_valid_groups=np.concatenate(all_valid_groups)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7eed158e9e4202c",
   "metadata": {},
   "source": [
    "# Train a FedAvg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f14dfe09d29fd8e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T18:30:50.769540Z",
     "start_time": "2024-09-04T18:24:39.580013Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 15:29:09.057746: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-21 15:29:09.210549: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Epoch 1/10\n",
      "73/73 [==============================] - 0s 958us/step - loss: 0.4850 - accuracy: 0.7803\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6577 - accuracy: 0.6197\n",
      "98/98 [==============================] - 0s 892us/step - loss: 0.5736 - accuracy: 0.7204\n",
      "47/47 [==============================] - 0s 904us/step - loss: 0.6000 - accuracy: 0.6931\n",
      "542/542 [==============================] - 1s 856us/step - loss: 0.5907 - accuracy: 0.6923\n",
      "69/69 [==============================] - 0s 917us/step - loss: 0.5574 - accuracy: 0.7381\n",
      "44/44 [==============================] - 0s 952us/step - loss: 0.5768 - accuracy: 0.7191\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.6273 - accuracy: 0.6531\n",
      "279/279 [==============================] - 1s 894us/step - loss: 0.4467 - accuracy: 0.8130\n",
      "148/148 [==============================] - 0s 900us/step - loss: 0.4305 - accuracy: 0.8202\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.5654 - accuracy: 0.7281\n",
      "24/24 [==============================] - 0s 916us/step - loss: 0.4873 - accuracy: 0.7965\n",
      "168/168 [==============================] - 0s 799us/step - loss: 0.5225 - accuracy: 0.7588\n",
      "96/96 [==============================] - 0s 821us/step - loss: 0.5156 - accuracy: 0.7642\n",
      "41/41 [==============================] - 0s 973us/step - loss: 0.5624 - accuracy: 0.7293\n",
      "41/41 [==============================] - 0s 972us/step - loss: 0.4585 - accuracy: 0.8083\n",
      "68/68 [==============================] - 0s 893us/step - loss: 0.5984 - accuracy: 0.6903\n",
      "66/66 [==============================] - 1s 1ms/step - loss: 0.6125 - accuracy: 0.6660\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5787 - accuracy: 0.6989\n",
      "71/71 [==============================] - 0s 951us/step - loss: 0.5606 - accuracy: 0.7328\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5677 - accuracy: 0.7214\n",
      "140/140 [==============================] - 0s 914us/step - loss: 0.5545 - accuracy: 0.7318\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.5613 - accuracy: 0.7321\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5147 - accuracy: 0.7602\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.4574 - accuracy: 0.8052\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.6058 - accuracy: 0.6806\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4794 - accuracy: 0.8073\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.5553 - accuracy: 0.7377\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.5510 - accuracy: 0.7438\n",
      "108/108 [==============================] - 0s 905us/step - loss: 0.5040 - accuracy: 0.7787\n",
      "31/31 [==============================] - 0s 973us/step - loss: 0.6590 - accuracy: 0.6082\n",
      "264/264 [==============================] - 1s 861us/step - loss: 0.5919 - accuracy: 0.6884\n",
      "146/146 [==============================] - 0s 924us/step - loss: 0.4607 - accuracy: 0.7994\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5170 - accuracy: 0.7958\n",
      "161/161 [==============================] - 0s 979us/step - loss: 0.5408 - accuracy: 0.7435\n",
      "59/59 [==============================] - 0s 965us/step - loss: 0.4870 - accuracy: 0.7825\n",
      "56/56 [==============================] - 1s 980us/step - loss: 0.5874 - accuracy: 0.7089\n",
      "173/173 [==============================] - 0s 1ms/step - loss: 0.5185 - accuracy: 0.7619\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6074 - accuracy: 0.6689\n",
      "74/74 [==============================] - 0s 921us/step - loss: 0.5032 - accuracy: 0.7714\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5161 - accuracy: 0.7938\n",
      "100/100 [==============================] - 0s 890us/step - loss: 0.5188 - accuracy: 0.7627\n",
      "387/387 [==============================] - 1s 824us/step - loss: 0.3973 - accuracy: 0.8409\n",
      "46/46 [==============================] - 0s 941us/step - loss: 0.3766 - accuracy: 0.8675\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6254\n",
      "108/108 [==============================] - 0s 920us/step - loss: 0.4267 - accuracy: 0.8285\n",
      "95/95 [==============================] - 0s 995us/step - loss: 0.5614 - accuracy: 0.7296\n",
      "28/28 [==============================] - 0s 952us/step - loss: 0.6281 - accuracy: 0.6603\n",
      "73/73 [==============================] - 0s 990us/step - loss: 0.5036 - accuracy: 0.7730\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4988 - accuracy: 0.8217\n",
      "10532/10532 [==============================] - 5s 505us/step - loss: 0.5316 - accuracy: 0.7591\n",
      "validation accuray: 0.7591038346290588\n",
      "Global Epoch 2/10\n",
      "73/73 [==============================] - 0s 928us/step - loss: 0.4499 - accuracy: 0.8002\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6231 - accuracy: 0.6622\n",
      "98/98 [==============================] - 0s 971us/step - loss: 0.5541 - accuracy: 0.7340\n",
      "47/47 [==============================] - 0s 972us/step - loss: 0.5646 - accuracy: 0.7282\n",
      "542/542 [==============================] - 1s 869us/step - loss: 0.5854 - accuracy: 0.6975\n",
      "69/69 [==============================] - 0s 953us/step - loss: 0.5328 - accuracy: 0.7550\n",
      "44/44 [==============================] - 0s 925us/step - loss: 0.5345 - accuracy: 0.7520\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5706 - accuracy: 0.7276\n",
      "279/279 [==============================] - 1s 875us/step - loss: 0.4331 - accuracy: 0.8202\n",
      "148/148 [==============================] - 0s 953us/step - loss: 0.4085 - accuracy: 0.8303\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.5089 - accuracy: 0.7738\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4149 - accuracy: 0.8343\n",
      "168/168 [==============================] - 0s 946us/step - loss: 0.5054 - accuracy: 0.7685\n",
      "96/96 [==============================] - 0s 912us/step - loss: 0.4896 - accuracy: 0.7808\n",
      "41/41 [==============================] - 0s 990us/step - loss: 0.5174 - accuracy: 0.7650\n",
      "41/41 [==============================] - 0s 939us/step - loss: 0.4068 - accuracy: 0.8345\n",
      "68/68 [==============================] - 0s 917us/step - loss: 0.5679 - accuracy: 0.7178\n",
      "66/66 [==============================] - 0s 947us/step - loss: 0.5897 - accuracy: 0.6944\n",
      "18/18 [==============================] - 0s 983us/step - loss: 0.4961 - accuracy: 0.7884\n",
      "71/71 [==============================] - 0s 930us/step - loss: 0.5363 - accuracy: 0.7488\n",
      "86/86 [==============================] - 0s 897us/step - loss: 0.5415 - accuracy: 0.7401\n",
      "140/140 [==============================] - 0s 868us/step - loss: 0.5356 - accuracy: 0.7444\n",
      "64/64 [==============================] - 0s 857us/step - loss: 0.5353 - accuracy: 0.7522\n",
      "47/47 [==============================] - 0s 947us/step - loss: 0.4638 - accuracy: 0.7922\n",
      "88/88 [==============================] - 0s 937us/step - loss: 0.4260 - accuracy: 0.8225\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5582 - accuracy: 0.7334\n",
      "25/25 [==============================] - 0s 946us/step - loss: 0.4086 - accuracy: 0.8373\n",
      "40/40 [==============================] - 0s 958us/step - loss: 0.5183 - accuracy: 0.7652\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4829 - accuracy: 0.7965\n",
      "108/108 [==============================] - 0s 931us/step - loss: 0.4775 - accuracy: 0.7939\n",
      "31/31 [==============================] - 0s 963us/step - loss: 0.6369 - accuracy: 0.6367\n",
      "264/264 [==============================] - 1s 861us/step - loss: 0.5811 - accuracy: 0.6970\n",
      "146/146 [==============================] - 0s 955us/step - loss: 0.4385 - accuracy: 0.8117\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4342 - accuracy: 0.8250\n",
      "161/161 [==============================] - 1s 932us/step - loss: 0.5192 - accuracy: 0.7562\n",
      "59/59 [==============================] - 0s 957us/step - loss: 0.4493 - accuracy: 0.8049\n",
      "56/56 [==============================] - 0s 952us/step - loss: 0.5603 - accuracy: 0.7327\n",
      "173/173 [==============================] - 0s 855us/step - loss: 0.5006 - accuracy: 0.7720\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5442 - accuracy: 0.7501\n",
      "74/74 [==============================] - 0s 883us/step - loss: 0.4693 - accuracy: 0.7936\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4229 - accuracy: 0.8250\n",
      "100/100 [==============================] - 0s 978us/step - loss: 0.4975 - accuracy: 0.7761\n",
      "387/387 [==============================] - 1s 923us/step - loss: 0.3872 - accuracy: 0.8443\n",
      "46/46 [==============================] - 0s 942us/step - loss: 0.3285 - accuracy: 0.8808\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5900 - accuracy: 0.7095\n",
      "108/108 [==============================] - 0s 930us/step - loss: 0.3954 - accuracy: 0.8402\n",
      "95/95 [==============================] - 0s 920us/step - loss: 0.5370 - accuracy: 0.7452\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5807 - accuracy: 0.7168\n",
      "73/73 [==============================] - 0s 885us/step - loss: 0.4719 - accuracy: 0.7922\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3913 - accuracy: 0.8428\n",
      "10532/10532 [==============================] - 5s 491us/step - loss: 0.5172 - accuracy: 0.7636\n",
      "validation accuray: 0.7636083364486694\n",
      "Global Epoch 3/10\n",
      "73/73 [==============================] - 0s 872us/step - loss: 0.4363 - accuracy: 0.8071\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6118 - accuracy: 0.6676\n",
      "98/98 [==============================] - 0s 936us/step - loss: 0.5469 - accuracy: 0.7385\n",
      "47/47 [==============================] - 0s 895us/step - loss: 0.5485 - accuracy: 0.7386\n",
      "542/542 [==============================] - 1s 882us/step - loss: 0.5817 - accuracy: 0.6987\n",
      "69/69 [==============================] - 0s 907us/step - loss: 0.5245 - accuracy: 0.7600\n",
      "44/44 [==============================] - 0s 955us/step - loss: 0.5223 - accuracy: 0.7566\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5472 - accuracy: 0.7426\n",
      "279/279 [==============================] - 1s 834us/step - loss: 0.4296 - accuracy: 0.8208\n",
      "148/148 [==============================] - 0s 865us/step - loss: 0.4024 - accuracy: 0.8328\n",
      "19/19 [==============================] - 0s 997us/step - loss: 0.4996 - accuracy: 0.7745\n",
      "24/24 [==============================] - 0s 930us/step - loss: 0.4106 - accuracy: 0.8364\n",
      "168/168 [==============================] - 0s 914us/step - loss: 0.4954 - accuracy: 0.7718\n",
      "96/96 [==============================] - 0s 881us/step - loss: 0.4798 - accuracy: 0.7847\n",
      "41/41 [==============================] - 0s 936us/step - loss: 0.5035 - accuracy: 0.7709\n",
      "41/41 [==============================] - 1s 972us/step - loss: 0.3977 - accuracy: 0.8388\n",
      "68/68 [==============================] - 0s 977us/step - loss: 0.5523 - accuracy: 0.7283\n",
      "66/66 [==============================] - 0s 945us/step - loss: 0.5760 - accuracy: 0.7054\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4820 - accuracy: 0.7924\n",
      "71/71 [==============================] - 0s 960us/step - loss: 0.5276 - accuracy: 0.7544\n",
      "86/86 [==============================] - 0s 999us/step - loss: 0.5272 - accuracy: 0.7470\n",
      "140/140 [==============================] - 0s 907us/step - loss: 0.5244 - accuracy: 0.7500\n",
      "64/64 [==============================] - 0s 927us/step - loss: 0.5222 - accuracy: 0.7531\n",
      "47/47 [==============================] - 0s 953us/step - loss: 0.4492 - accuracy: 0.7991\n",
      "88/88 [==============================] - 0s 981us/step - loss: 0.4176 - accuracy: 0.8249\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5440 - accuracy: 0.7408\n",
      "25/25 [==============================] - 0s 942us/step - loss: 0.3969 - accuracy: 0.8395\n",
      "40/40 [==============================] - 0s 935us/step - loss: 0.5096 - accuracy: 0.7719\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4698 - accuracy: 0.8003\n",
      "108/108 [==============================] - 0s 969us/step - loss: 0.4691 - accuracy: 0.7959\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.6235 - accuracy: 0.6541\n",
      "264/264 [==============================] - 1s 869us/step - loss: 0.5724 - accuracy: 0.7033\n",
      "146/146 [==============================] - 0s 849us/step - loss: 0.4311 - accuracy: 0.8139\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4215 - accuracy: 0.8321\n",
      "161/161 [==============================] - 0s 909us/step - loss: 0.5094 - accuracy: 0.7599\n",
      "59/59 [==============================] - 0s 922us/step - loss: 0.4412 - accuracy: 0.8090\n",
      "56/56 [==============================] - 0s 922us/step - loss: 0.5486 - accuracy: 0.7385\n",
      "173/173 [==============================] - 0s 881us/step - loss: 0.4914 - accuracy: 0.7747\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5251 - accuracy: 0.7618\n",
      "74/74 [==============================] - 0s 965us/step - loss: 0.4600 - accuracy: 0.7970\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4158 - accuracy: 0.8261\n",
      "100/100 [==============================] - 0s 944us/step - loss: 0.4878 - accuracy: 0.7793\n",
      "387/387 [==============================] - 1s 963us/step - loss: 0.3842 - accuracy: 0.8458\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.3197 - accuracy: 0.8854\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5724 - accuracy: 0.7182\n",
      "108/108 [==============================] - 0s 905us/step - loss: 0.3893 - accuracy: 0.8422\n",
      "95/95 [==============================] - 0s 936us/step - loss: 0.5273 - accuracy: 0.7496\n",
      "28/28 [==============================] - 0s 962us/step - loss: 0.5669 - accuracy: 0.7204\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4629 - accuracy: 0.7964\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3813 - accuracy: 0.8550\n",
      "10532/10532 [==============================] - 5s 491us/step - loss: 0.5095 - accuracy: 0.7661\n",
      "validation accuray: 0.7660504579544067\n",
      "Global Epoch 4/10\n",
      "73/73 [==============================] - 0s 937us/step - loss: 0.4299 - accuracy: 0.8126\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6051 - accuracy: 0.6798\n",
      "98/98 [==============================] - 1s 996us/step - loss: 0.5408 - accuracy: 0.7397\n",
      "47/47 [==============================] - 0s 933us/step - loss: 0.5457 - accuracy: 0.7392\n",
      "542/542 [==============================] - 1s 864us/step - loss: 0.5791 - accuracy: 0.7004\n",
      "69/69 [==============================] - 0s 876us/step - loss: 0.5167 - accuracy: 0.7624\n",
      "44/44 [==============================] - 0s 910us/step - loss: 0.5110 - accuracy: 0.7638\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5381 - accuracy: 0.7409\n",
      "279/279 [==============================] - 1s 863us/step - loss: 0.4263 - accuracy: 0.8215\n",
      "148/148 [==============================] - 0s 913us/step - loss: 0.3982 - accuracy: 0.8358\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.4983 - accuracy: 0.7736\n",
      "24/24 [==============================] - 0s 984us/step - loss: 0.4007 - accuracy: 0.8381\n",
      "168/168 [==============================] - 0s 895us/step - loss: 0.4903 - accuracy: 0.7740\n",
      "96/96 [==============================] - 0s 927us/step - loss: 0.4736 - accuracy: 0.7865\n",
      "41/41 [==============================] - 0s 903us/step - loss: 0.4960 - accuracy: 0.7730\n",
      "41/41 [==============================] - 0s 983us/step - loss: 0.3925 - accuracy: 0.8408\n",
      "68/68 [==============================] - 0s 943us/step - loss: 0.5469 - accuracy: 0.7299\n",
      "66/66 [==============================] - 0s 942us/step - loss: 0.5686 - accuracy: 0.7119\n",
      "18/18 [==============================] - 0s 995us/step - loss: 0.4726 - accuracy: 0.7950\n",
      "71/71 [==============================] - 0s 950us/step - loss: 0.5211 - accuracy: 0.7584\n",
      "86/86 [==============================] - 0s 985us/step - loss: 0.5189 - accuracy: 0.7515\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.5167 - accuracy: 0.7539\n",
      "64/64 [==============================] - 0s 944us/step - loss: 0.5160 - accuracy: 0.7576\n",
      "47/47 [==============================] - 0s 935us/step - loss: 0.4435 - accuracy: 0.8036\n",
      "88/88 [==============================] - 0s 926us/step - loss: 0.4126 - accuracy: 0.8265\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5349 - accuracy: 0.7482\n",
      "25/25 [==============================] - 0s 883us/step - loss: 0.3904 - accuracy: 0.8411\n",
      "40/40 [==============================] - 0s 919us/step - loss: 0.5015 - accuracy: 0.7733\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4564 - accuracy: 0.8045\n",
      "108/108 [==============================] - 0s 898us/step - loss: 0.4637 - accuracy: 0.7983\n",
      "31/31 [==============================] - 0s 915us/step - loss: 0.6155 - accuracy: 0.6584\n",
      "264/264 [==============================] - 1s 889us/step - loss: 0.5692 - accuracy: 0.7044\n",
      "146/146 [==============================] - 0s 883us/step - loss: 0.4261 - accuracy: 0.8161\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4163 - accuracy: 0.8321\n",
      "161/161 [==============================] - 0s 902us/step - loss: 0.5033 - accuracy: 0.7634\n",
      "59/59 [==============================] - 0s 962us/step - loss: 0.4359 - accuracy: 0.8123\n",
      "56/56 [==============================] - 0s 947us/step - loss: 0.5432 - accuracy: 0.7388\n",
      "173/173 [==============================] - 0s 899us/step - loss: 0.4850 - accuracy: 0.7791\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5139 - accuracy: 0.7669\n",
      "74/74 [==============================] - 0s 936us/step - loss: 0.4534 - accuracy: 0.8017\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4083 - accuracy: 0.8264\n",
      "100/100 [==============================] - 0s 886us/step - loss: 0.4810 - accuracy: 0.7824\n",
      "387/387 [==============================] - 1s 883us/step - loss: 0.3814 - accuracy: 0.8466\n",
      "46/46 [==============================] - 0s 935us/step - loss: 0.3125 - accuracy: 0.8900\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5654 - accuracy: 0.7235\n",
      "108/108 [==============================] - 0s 969us/step - loss: 0.3842 - accuracy: 0.8446\n",
      "95/95 [==============================] - 0s 951us/step - loss: 0.5193 - accuracy: 0.7551\n",
      "28/28 [==============================] - 0s 996us/step - loss: 0.5540 - accuracy: 0.7281\n",
      "73/73 [==============================] - 0s 968us/step - loss: 0.4547 - accuracy: 0.8016\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3741 - accuracy: 0.8534\n",
      "10532/10532 [==============================] - 5s 501us/step - loss: 0.5046 - accuracy: 0.7683\n",
      "validation accuray: 0.7682996988296509\n",
      "Global Epoch 5/10\n",
      "73/73 [==============================] - 0s 909us/step - loss: 0.4247 - accuracy: 0.8140\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6009 - accuracy: 0.6866\n",
      "98/98 [==============================] - 0s 921us/step - loss: 0.5363 - accuracy: 0.7417\n",
      "47/47 [==============================] - 0s 966us/step - loss: 0.5347 - accuracy: 0.7456\n",
      "542/542 [==============================] - 1s 881us/step - loss: 0.5771 - accuracy: 0.7014\n",
      "69/69 [==============================] - 0s 922us/step - loss: 0.5126 - accuracy: 0.7649\n",
      "44/44 [==============================] - 0s 945us/step - loss: 0.5021 - accuracy: 0.7697\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5294 - accuracy: 0.7450\n",
      "279/279 [==============================] - 1s 856us/step - loss: 0.4233 - accuracy: 0.8230\n",
      "148/148 [==============================] - 0s 876us/step - loss: 0.3950 - accuracy: 0.8357\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.4896 - accuracy: 0.7751\n",
      "24/24 [==============================] - 0s 981us/step - loss: 0.3972 - accuracy: 0.8402\n",
      "168/168 [==============================] - 0s 898us/step - loss: 0.4862 - accuracy: 0.7750\n",
      "96/96 [==============================] - 0s 930us/step - loss: 0.4715 - accuracy: 0.7885\n",
      "41/41 [==============================] - 0s 938us/step - loss: 0.4901 - accuracy: 0.7748\n",
      "41/41 [==============================] - 0s 919us/step - loss: 0.3880 - accuracy: 0.8418\n",
      "68/68 [==============================] - 0s 977us/step - loss: 0.5400 - accuracy: 0.7342\n",
      "66/66 [==============================] - 0s 913us/step - loss: 0.5612 - accuracy: 0.7170\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4687 - accuracy: 0.7990\n",
      "71/71 [==============================] - 0s 935us/step - loss: 0.5151 - accuracy: 0.7589\n",
      "86/86 [==============================] - 0s 905us/step - loss: 0.5139 - accuracy: 0.7535\n",
      "140/140 [==============================] - 0s 886us/step - loss: 0.5130 - accuracy: 0.7564\n",
      "64/64 [==============================] - 0s 922us/step - loss: 0.5127 - accuracy: 0.7595\n",
      "47/47 [==============================] - 0s 974us/step - loss: 0.4408 - accuracy: 0.8075\n",
      "88/88 [==============================] - 0s 936us/step - loss: 0.4085 - accuracy: 0.8284\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5308 - accuracy: 0.7479\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3865 - accuracy: 0.8422\n",
      "40/40 [==============================] - 0s 963us/step - loss: 0.4965 - accuracy: 0.7747\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4528 - accuracy: 0.8057\n",
      "108/108 [==============================] - 0s 913us/step - loss: 0.4595 - accuracy: 0.8008\n",
      "31/31 [==============================] - 0s 963us/step - loss: 0.6147 - accuracy: 0.6553\n",
      "264/264 [==============================] - 1s 840us/step - loss: 0.5648 - accuracy: 0.7067\n",
      "146/146 [==============================] - 0s 870us/step - loss: 0.4233 - accuracy: 0.8170\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4120 - accuracy: 0.8347\n",
      "161/161 [==============================] - 0s 885us/step - loss: 0.4994 - accuracy: 0.7651\n",
      "59/59 [==============================] - 0s 919us/step - loss: 0.4326 - accuracy: 0.8122\n",
      "56/56 [==============================] - 0s 994us/step - loss: 0.5369 - accuracy: 0.7416\n",
      "173/173 [==============================] - 0s 964us/step - loss: 0.4811 - accuracy: 0.7792\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5061 - accuracy: 0.7681\n",
      "74/74 [==============================] - 0s 915us/step - loss: 0.4490 - accuracy: 0.8025\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4070 - accuracy: 0.8222\n",
      "100/100 [==============================] - 0s 972us/step - loss: 0.4768 - accuracy: 0.7835\n",
      "387/387 [==============================] - 1s 876us/step - loss: 0.3788 - accuracy: 0.8482\n",
      "46/46 [==============================] - 0s 954us/step - loss: 0.3103 - accuracy: 0.8892\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5595 - accuracy: 0.7250\n",
      "108/108 [==============================] - 2s 946us/step - loss: 0.3811 - accuracy: 0.8442\n",
      "95/95 [==============================] - 0s 955us/step - loss: 0.5159 - accuracy: 0.7564\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5484 - accuracy: 0.7318\n",
      "73/73 [==============================] - 0s 975us/step - loss: 0.4501 - accuracy: 0.8020\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3709 - accuracy: 0.8534\n",
      "10532/10532 [==============================] - 5s 492us/step - loss: 0.5010 - accuracy: 0.7697\n",
      "validation accuray: 0.7697388529777527\n",
      "Global Epoch 6/10\n",
      "73/73 [==============================] - 0s 917us/step - loss: 0.4181 - accuracy: 0.8201\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5932 - accuracy: 0.6942\n",
      "98/98 [==============================] - 0s 951us/step - loss: 0.5331 - accuracy: 0.7421\n",
      "47/47 [==============================] - 0s 913us/step - loss: 0.5310 - accuracy: 0.7453\n",
      "542/542 [==============================] - 1s 843us/step - loss: 0.5756 - accuracy: 0.7026\n",
      "69/69 [==============================] - 0s 934us/step - loss: 0.5081 - accuracy: 0.7683\n",
      "44/44 [==============================] - 0s 985us/step - loss: 0.5004 - accuracy: 0.7675\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5239 - accuracy: 0.7482\n",
      "279/279 [==============================] - 1s 860us/step - loss: 0.4201 - accuracy: 0.8244\n",
      "148/148 [==============================] - 0s 844us/step - loss: 0.3914 - accuracy: 0.8385\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.4873 - accuracy: 0.7749\n",
      "24/24 [==============================] - 0s 918us/step - loss: 0.3970 - accuracy: 0.8405\n",
      "168/168 [==============================] - 0s 880us/step - loss: 0.4823 - accuracy: 0.7777\n",
      "96/96 [==============================] - 0s 937us/step - loss: 0.4668 - accuracy: 0.7901\n",
      "41/41 [==============================] - 0s 922us/step - loss: 0.4874 - accuracy: 0.7782\n",
      "41/41 [==============================] - 0s 969us/step - loss: 0.3865 - accuracy: 0.8444\n",
      "68/68 [==============================] - 0s 939us/step - loss: 0.5361 - accuracy: 0.7359\n",
      "66/66 [==============================] - 0s 920us/step - loss: 0.5579 - accuracy: 0.7168\n",
      "18/18 [==============================] - 0s 985us/step - loss: 0.4626 - accuracy: 0.7988\n",
      "71/71 [==============================] - 0s 971us/step - loss: 0.5120 - accuracy: 0.7613\n",
      "86/86 [==============================] - 0s 979us/step - loss: 0.5112 - accuracy: 0.7562\n",
      "140/140 [==============================] - 0s 874us/step - loss: 0.5077 - accuracy: 0.7592\n",
      "64/64 [==============================] - 0s 887us/step - loss: 0.5102 - accuracy: 0.7617\n",
      "47/47 [==============================] - 0s 916us/step - loss: 0.4375 - accuracy: 0.8097\n",
      "88/88 [==============================] - 0s 867us/step - loss: 0.4059 - accuracy: 0.8285\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5258 - accuracy: 0.7471\n",
      "25/25 [==============================] - 0s 954us/step - loss: 0.3854 - accuracy: 0.8413\n",
      "40/40 [==============================] - 0s 946us/step - loss: 0.4939 - accuracy: 0.7736\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4481 - accuracy: 0.8059\n",
      "108/108 [==============================] - 0s 963us/step - loss: 0.4559 - accuracy: 0.8015\n",
      "31/31 [==============================] - 0s 951us/step - loss: 0.6074 - accuracy: 0.6633\n",
      "264/264 [==============================] - 1s 899us/step - loss: 0.5621 - accuracy: 0.7087\n",
      "146/146 [==============================] - 0s 927us/step - loss: 0.4210 - accuracy: 0.8190\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4083 - accuracy: 0.8338\n",
      "161/161 [==============================] - 0s 858us/step - loss: 0.4950 - accuracy: 0.7669\n",
      "59/59 [==============================] - 0s 851us/step - loss: 0.4309 - accuracy: 0.8152\n",
      "56/56 [==============================] - 0s 883us/step - loss: 0.5318 - accuracy: 0.7456\n",
      "173/173 [==============================] - 0s 895us/step - loss: 0.4771 - accuracy: 0.7820\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5050 - accuracy: 0.7711\n",
      "74/74 [==============================] - 0s 985us/step - loss: 0.4446 - accuracy: 0.8054\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4008 - accuracy: 0.8282\n",
      "100/100 [==============================] - 0s 915us/step - loss: 0.4726 - accuracy: 0.7871\n",
      "387/387 [==============================] - 1s 889us/step - loss: 0.3767 - accuracy: 0.8493\n",
      "46/46 [==============================] - 0s 901us/step - loss: 0.3074 - accuracy: 0.8883\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5547 - accuracy: 0.7342\n",
      "108/108 [==============================] - 0s 862us/step - loss: 0.3791 - accuracy: 0.8460\n",
      "95/95 [==============================] - 0s 956us/step - loss: 0.5114 - accuracy: 0.7593\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5431 - accuracy: 0.7340\n",
      "73/73 [==============================] - 0s 891us/step - loss: 0.4455 - accuracy: 0.8056\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3692 - accuracy: 0.8565\n",
      "10532/10532 [==============================] - 5s 481us/step - loss: 0.4981 - accuracy: 0.7710\n",
      "validation accuray: 0.7709643840789795\n",
      "Global Epoch 7/10\n",
      "73/73 [==============================] - 0s 933us/step - loss: 0.4178 - accuracy: 0.8201\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5922 - accuracy: 0.6832\n",
      "98/98 [==============================] - 0s 914us/step - loss: 0.5294 - accuracy: 0.7454\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5297 - accuracy: 0.7454\n",
      "542/542 [==============================] - 1s 866us/step - loss: 0.5732 - accuracy: 0.7039\n",
      "69/69 [==============================] - 2s 969us/step - loss: 0.5050 - accuracy: 0.7670\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.4933 - accuracy: 0.7735\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5231 - accuracy: 0.7482\n",
      "279/279 [==============================] - 1s 844us/step - loss: 0.4190 - accuracy: 0.8249\n",
      "148/148 [==============================] - 0s 931us/step - loss: 0.3884 - accuracy: 0.8405\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.4832 - accuracy: 0.7781\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3943 - accuracy: 0.8422\n",
      "168/168 [==============================] - 0s 871us/step - loss: 0.4796 - accuracy: 0.7798\n",
      "96/96 [==============================] - 0s 935us/step - loss: 0.4640 - accuracy: 0.7916\n",
      "41/41 [==============================] - 0s 928us/step - loss: 0.4839 - accuracy: 0.7780\n",
      "41/41 [==============================] - 0s 981us/step - loss: 0.3833 - accuracy: 0.8443\n",
      "68/68 [==============================] - 0s 931us/step - loss: 0.5332 - accuracy: 0.7419\n",
      "66/66 [==============================] - 0s 912us/step - loss: 0.5539 - accuracy: 0.7198\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4599 - accuracy: 0.7992\n",
      "71/71 [==============================] - 0s 957us/step - loss: 0.5097 - accuracy: 0.7621\n",
      "86/86 [==============================] - 0s 969us/step - loss: 0.5069 - accuracy: 0.7575\n",
      "140/140 [==============================] - 0s 926us/step - loss: 0.5050 - accuracy: 0.7606\n",
      "64/64 [==============================] - 0s 843us/step - loss: 0.5054 - accuracy: 0.7633\n",
      "47/47 [==============================] - 0s 877us/step - loss: 0.4322 - accuracy: 0.8101\n",
      "88/88 [==============================] - 0s 925us/step - loss: 0.4039 - accuracy: 0.8295\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5214 - accuracy: 0.7468\n",
      "25/25 [==============================] - 0s 945us/step - loss: 0.3824 - accuracy: 0.8414\n",
      "40/40 [==============================] - 0s 936us/step - loss: 0.4903 - accuracy: 0.7762\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4446 - accuracy: 0.8078\n",
      "108/108 [==============================] - 0s 910us/step - loss: 0.4519 - accuracy: 0.8017\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.6076 - accuracy: 0.6667\n",
      "264/264 [==============================] - 1s 900us/step - loss: 0.5596 - accuracy: 0.7112\n",
      "146/146 [==============================] - 0s 884us/step - loss: 0.4174 - accuracy: 0.8196\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4045 - accuracy: 0.8299\n",
      "161/161 [==============================] - 0s 907us/step - loss: 0.4912 - accuracy: 0.7683\n",
      "59/59 [==============================] - 0s 927us/step - loss: 0.4277 - accuracy: 0.8150\n",
      "56/56 [==============================] - 0s 906us/step - loss: 0.5284 - accuracy: 0.7468\n",
      "173/173 [==============================] - 0s 908us/step - loss: 0.4740 - accuracy: 0.7826\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4969 - accuracy: 0.7741\n",
      "74/74 [==============================] - 0s 926us/step - loss: 0.4429 - accuracy: 0.8022\n",
      "12/12 [==============================] - 0s 993us/step - loss: 0.4068 - accuracy: 0.8243\n",
      "100/100 [==============================] - 0s 860us/step - loss: 0.4698 - accuracy: 0.7884\n",
      "387/387 [==============================] - 1s 898us/step - loss: 0.3756 - accuracy: 0.8498\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.3066 - accuracy: 0.8898\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5473 - accuracy: 0.7332\n",
      "108/108 [==============================] - 0s 877us/step - loss: 0.3762 - accuracy: 0.8480\n",
      "95/95 [==============================] - 0s 897us/step - loss: 0.5080 - accuracy: 0.7613\n",
      "28/28 [==============================] - 0s 950us/step - loss: 0.5405 - accuracy: 0.7375\n",
      "73/73 [==============================] - 0s 940us/step - loss: 0.4428 - accuracy: 0.8054\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3742 - accuracy: 0.8476\n",
      "10532/10532 [==============================] - 5s 505us/step - loss: 0.4956 - accuracy: 0.7722\n",
      "validation accuray: 0.772228479385376\n",
      "Global Epoch 8/10\n",
      "73/73 [==============================] - 0s 922us/step - loss: 0.4153 - accuracy: 0.8204\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5882 - accuracy: 0.6874\n",
      "98/98 [==============================] - 0s 952us/step - loss: 0.5284 - accuracy: 0.7463\n",
      "47/47 [==============================] - 0s 994us/step - loss: 0.5224 - accuracy: 0.7484\n",
      "542/542 [==============================] - 1s 903us/step - loss: 0.5723 - accuracy: 0.7052\n",
      "69/69 [==============================] - 0s 985us/step - loss: 0.5043 - accuracy: 0.7677\n",
      "44/44 [==============================] - 0s 888us/step - loss: 0.4899 - accuracy: 0.7737\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5156 - accuracy: 0.7513\n",
      "279/279 [==============================] - 1s 948us/step - loss: 0.4174 - accuracy: 0.8255\n",
      "148/148 [==============================] - 0s 896us/step - loss: 0.3864 - accuracy: 0.8415\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.4817 - accuracy: 0.7777\n",
      "24/24 [==============================] - 0s 953us/step - loss: 0.3925 - accuracy: 0.8413\n",
      "168/168 [==============================] - 0s 933us/step - loss: 0.4773 - accuracy: 0.7806\n",
      "96/96 [==============================] - 0s 848us/step - loss: 0.4623 - accuracy: 0.7935\n",
      "41/41 [==============================] - 0s 936us/step - loss: 0.4798 - accuracy: 0.7810\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3798 - accuracy: 0.8459\n",
      "68/68 [==============================] - 0s 883us/step - loss: 0.5302 - accuracy: 0.7432\n",
      "66/66 [==============================] - 0s 985us/step - loss: 0.5496 - accuracy: 0.7245\n",
      "18/18 [==============================] - 0s 948us/step - loss: 0.4603 - accuracy: 0.8004\n",
      "71/71 [==============================] - 0s 960us/step - loss: 0.5063 - accuracy: 0.7632\n",
      "86/86 [==============================] - 0s 915us/step - loss: 0.5052 - accuracy: 0.7593\n",
      "140/140 [==============================] - 0s 897us/step - loss: 0.5016 - accuracy: 0.7639\n",
      "64/64 [==============================] - 0s 972us/step - loss: 0.5033 - accuracy: 0.7640\n",
      "47/47 [==============================] - 0s 944us/step - loss: 0.4291 - accuracy: 0.8130\n",
      "88/88 [==============================] - 0s 851us/step - loss: 0.4019 - accuracy: 0.8314\n",
      "14/14 [==============================] - 2s 1ms/step - loss: 0.5204 - accuracy: 0.7499\n",
      "25/25 [==============================] - 0s 940us/step - loss: 0.3799 - accuracy: 0.8430\n",
      "40/40 [==============================] - 0s 918us/step - loss: 0.4880 - accuracy: 0.7770\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4387 - accuracy: 0.8127\n",
      "108/108 [==============================] - 0s 899us/step - loss: 0.4502 - accuracy: 0.8032\n",
      "31/31 [==============================] - 0s 964us/step - loss: 0.6041 - accuracy: 0.6657\n",
      "264/264 [==============================] - 1s 850us/step - loss: 0.5571 - accuracy: 0.7126\n",
      "146/146 [==============================] - 0s 877us/step - loss: 0.4152 - accuracy: 0.8200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4023 - accuracy: 0.8303\n",
      "161/161 [==============================] - 0s 926us/step - loss: 0.4883 - accuracy: 0.7695\n",
      "59/59 [==============================] - 0s 910us/step - loss: 0.4265 - accuracy: 0.8160\n",
      "56/56 [==============================] - 0s 980us/step - loss: 0.5258 - accuracy: 0.7485\n",
      "173/173 [==============================] - 0s 901us/step - loss: 0.4725 - accuracy: 0.7851\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4896 - accuracy: 0.7741\n",
      "74/74 [==============================] - 0s 931us/step - loss: 0.4399 - accuracy: 0.8060\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4007 - accuracy: 0.8247\n",
      "100/100 [==============================] - 0s 910us/step - loss: 0.4661 - accuracy: 0.7879\n",
      "387/387 [==============================] - 1s 861us/step - loss: 0.3734 - accuracy: 0.8502\n",
      "46/46 [==============================] - 0s 907us/step - loss: 0.3052 - accuracy: 0.8896\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5481 - accuracy: 0.7318\n",
      "108/108 [==============================] - 0s 931us/step - loss: 0.3735 - accuracy: 0.8477\n",
      "95/95 [==============================] - 0s 908us/step - loss: 0.5045 - accuracy: 0.7643\n",
      "28/28 [==============================] - 0s 969us/step - loss: 0.5351 - accuracy: 0.7386\n",
      "73/73 [==============================] - 0s 910us/step - loss: 0.4397 - accuracy: 0.8072\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3716 - accuracy: 0.8534\n",
      "10532/10532 [==============================] - 5s 481us/step - loss: 0.4939 - accuracy: 0.7731\n",
      "validation accuray: 0.7730652689933777\n",
      "Global Epoch 9/10\n",
      "73/73 [==============================] - 0s 829us/step - loss: 0.4117 - accuracy: 0.8209\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5800 - accuracy: 0.6937\n",
      "98/98 [==============================] - 0s 919us/step - loss: 0.5261 - accuracy: 0.7474\n",
      "47/47 [==============================] - 0s 918us/step - loss: 0.5219 - accuracy: 0.7477\n",
      "542/542 [==============================] - 1s 886us/step - loss: 0.5713 - accuracy: 0.7047\n",
      "69/69 [==============================] - 0s 900us/step - loss: 0.5007 - accuracy: 0.7695\n",
      "44/44 [==============================] - 0s 979us/step - loss: 0.4883 - accuracy: 0.7764\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5149 - accuracy: 0.7506\n",
      "279/279 [==============================] - 1s 889us/step - loss: 0.4148 - accuracy: 0.8268\n",
      "148/148 [==============================] - 0s 878us/step - loss: 0.3862 - accuracy: 0.8419\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.4790 - accuracy: 0.7781\n",
      "24/24 [==============================] - 0s 996us/step - loss: 0.3900 - accuracy: 0.8400\n",
      "168/168 [==============================] - 0s 854us/step - loss: 0.4752 - accuracy: 0.7803\n",
      "96/96 [==============================] - 0s 927us/step - loss: 0.4596 - accuracy: 0.7931\n",
      "41/41 [==============================] - 0s 945us/step - loss: 0.4763 - accuracy: 0.7832\n",
      "41/41 [==============================] - 0s 931us/step - loss: 0.3777 - accuracy: 0.8465\n",
      "68/68 [==============================] - 0s 931us/step - loss: 0.5256 - accuracy: 0.7436\n",
      "66/66 [==============================] - 0s 887us/step - loss: 0.5482 - accuracy: 0.7226\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4549 - accuracy: 0.8035\n",
      "71/71 [==============================] - 0s 972us/step - loss: 0.5065 - accuracy: 0.7625\n",
      "86/86 [==============================] - 0s 932us/step - loss: 0.5004 - accuracy: 0.7640\n",
      "140/140 [==============================] - 0s 829us/step - loss: 0.4997 - accuracy: 0.7623\n",
      "64/64 [==============================] - 0s 986us/step - loss: 0.4994 - accuracy: 0.7647\n",
      "47/47 [==============================] - 0s 951us/step - loss: 0.4275 - accuracy: 0.8142\n",
      "88/88 [==============================] - 0s 888us/step - loss: 0.4007 - accuracy: 0.8315\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5162 - accuracy: 0.7539\n",
      "25/25 [==============================] - 0s 922us/step - loss: 0.3775 - accuracy: 0.8459\n",
      "40/40 [==============================] - 0s 968us/step - loss: 0.4864 - accuracy: 0.7776\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4371 - accuracy: 0.8142\n",
      "108/108 [==============================] - 0s 916us/step - loss: 0.4481 - accuracy: 0.8030\n",
      "31/31 [==============================] - 0s 959us/step - loss: 0.5999 - accuracy: 0.6718\n",
      "264/264 [==============================] - 1s 862us/step - loss: 0.5549 - accuracy: 0.7125\n",
      "146/146 [==============================] - 0s 933us/step - loss: 0.4142 - accuracy: 0.8213\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3989 - accuracy: 0.8321\n",
      "161/161 [==============================] - 0s 911us/step - loss: 0.4860 - accuracy: 0.7713\n",
      "59/59 [==============================] - 0s 938us/step - loss: 0.4236 - accuracy: 0.8175\n",
      "56/56 [==============================] - 0s 952us/step - loss: 0.5213 - accuracy: 0.7513\n",
      "173/173 [==============================] - 0s 926us/step - loss: 0.4688 - accuracy: 0.7864\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4883 - accuracy: 0.7735\n",
      "74/74 [==============================] - 0s 958us/step - loss: 0.4376 - accuracy: 0.8068\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.3998 - accuracy: 0.8317\n",
      "100/100 [==============================] - 0s 885us/step - loss: 0.4643 - accuracy: 0.7898\n",
      "387/387 [==============================] - 1s 855us/step - loss: 0.3716 - accuracy: 0.8514\n",
      "46/46 [==============================] - 0s 916us/step - loss: 0.3021 - accuracy: 0.8928\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5504 - accuracy: 0.7347\n",
      "108/108 [==============================] - 0s 882us/step - loss: 0.3716 - accuracy: 0.8485\n",
      "95/95 [==============================] - 0s 868us/step - loss: 0.5030 - accuracy: 0.7646\n",
      "28/28 [==============================] - 0s 921us/step - loss: 0.5393 - accuracy: 0.7370\n",
      "73/73 [==============================] - 0s 916us/step - loss: 0.4370 - accuracy: 0.8074\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3679 - accuracy: 0.8539\n",
      "10532/10532 [==============================] - 5s 496us/step - loss: 0.4917 - accuracy: 0.7738\n",
      "validation accuray: 0.7738041281700134\n",
      "Global Epoch 10/10\n",
      "73/73 [==============================] - 0s 912us/step - loss: 0.4073 - accuracy: 0.8262\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5796 - accuracy: 0.6904\n",
      "98/98 [==============================] - 0s 886us/step - loss: 0.5244 - accuracy: 0.7480\n",
      "47/47 [==============================] - 0s 925us/step - loss: 0.5196 - accuracy: 0.7509\n",
      "542/542 [==============================] - 1s 866us/step - loss: 0.5698 - accuracy: 0.7060\n",
      "69/69 [==============================] - 0s 872us/step - loss: 0.4975 - accuracy: 0.7720\n",
      "44/44 [==============================] - 0s 940us/step - loss: 0.4855 - accuracy: 0.7786\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5167 - accuracy: 0.7524\n",
      "279/279 [==============================] - 3s 886us/step - loss: 0.4138 - accuracy: 0.8271\n",
      "148/148 [==============================] - 0s 908us/step - loss: 0.3831 - accuracy: 0.8428\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.4772 - accuracy: 0.7813\n",
      "24/24 [==============================] - 0s 958us/step - loss: 0.3878 - accuracy: 0.8466\n",
      "168/168 [==============================] - 1s 1ms/step - loss: 0.4730 - accuracy: 0.7821\n",
      "96/96 [==============================] - 0s 927us/step - loss: 0.4592 - accuracy: 0.7935\n",
      "41/41 [==============================] - 0s 946us/step - loss: 0.4739 - accuracy: 0.7862\n",
      "41/41 [==============================] - 0s 945us/step - loss: 0.3779 - accuracy: 0.8467\n",
      "68/68 [==============================] - 0s 931us/step - loss: 0.5222 - accuracy: 0.7461\n",
      "66/66 [==============================] - 0s 914us/step - loss: 0.5449 - accuracy: 0.7286\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.8026\n",
      "71/71 [==============================] - 0s 914us/step - loss: 0.5040 - accuracy: 0.7660\n",
      "86/86 [==============================] - 0s 940us/step - loss: 0.4990 - accuracy: 0.7623\n",
      "140/140 [==============================] - 0s 948us/step - loss: 0.4972 - accuracy: 0.7627\n",
      "64/64 [==============================] - 0s 960us/step - loss: 0.4966 - accuracy: 0.7670\n",
      "47/47 [==============================] - 0s 998us/step - loss: 0.4245 - accuracy: 0.8154\n",
      "88/88 [==============================] - 0s 926us/step - loss: 0.3993 - accuracy: 0.8307\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5191 - accuracy: 0.7499\n",
      "25/25 [==============================] - 0s 962us/step - loss: 0.3746 - accuracy: 0.8470\n",
      "40/40 [==============================] - 0s 968us/step - loss: 0.4837 - accuracy: 0.7786\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4341 - accuracy: 0.8127\n",
      "108/108 [==============================] - 0s 888us/step - loss: 0.4461 - accuracy: 0.8035\n",
      "31/31 [==============================] - 0s 980us/step - loss: 0.6049 - accuracy: 0.6706\n",
      "264/264 [==============================] - 1s 881us/step - loss: 0.5535 - accuracy: 0.7152\n",
      "146/146 [==============================] - 0s 970us/step - loss: 0.4138 - accuracy: 0.8223\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3961 - accuracy: 0.8361\n",
      "161/161 [==============================] - 0s 863us/step - loss: 0.4831 - accuracy: 0.7738\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.4234 - accuracy: 0.8193\n",
      "56/56 [==============================] - 0s 935us/step - loss: 0.5189 - accuracy: 0.7522\n",
      "173/173 [==============================] - 0s 861us/step - loss: 0.4685 - accuracy: 0.7867\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4868 - accuracy: 0.7750\n",
      "74/74 [==============================] - 0s 940us/step - loss: 0.4357 - accuracy: 0.8062\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4001 - accuracy: 0.8271\n",
      "100/100 [==============================] - 0s 927us/step - loss: 0.4623 - accuracy: 0.7909\n",
      "387/387 [==============================] - 1s 846us/step - loss: 0.3710 - accuracy: 0.8516\n",
      "46/46 [==============================] - 0s 901us/step - loss: 0.3021 - accuracy: 0.8927\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5453 - accuracy: 0.7347\n",
      "108/108 [==============================] - 0s 918us/step - loss: 0.3696 - accuracy: 0.8488\n",
      "95/95 [==============================] - 0s 927us/step - loss: 0.5005 - accuracy: 0.7637\n",
      "28/28 [==============================] - 0s 944us/step - loss: 0.5281 - accuracy: 0.7440\n",
      "73/73 [==============================] - 0s 980us/step - loss: 0.4356 - accuracy: 0.8081\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3695 - accuracy: 0.8518\n",
      "10532/10532 [==============================] - 5s 496us/step - loss: 0.4911 - accuracy: 0.7745\n",
      "validation accuray: 0.7744896411895752\n",
      "\n",
      "Evaluating Global Model\n",
      "AL - Loss: 0.4365, Accuracy: 0.8053\n",
      "AK - Loss: 0.5418, Accuracy: 0.7181\n",
      "AZ - Loss: 0.5374, Accuracy: 0.7432\n",
      "AR - Loss: 0.5248, Accuracy: 0.7471\n",
      "CA - Loss: 0.6152, Accuracy: 0.6980\n",
      "CO - Loss: 0.4925, Accuracy: 0.7777\n",
      "CT - Loss: 0.5163, Accuracy: 0.7563\n",
      "DE - Loss: 0.5090, Accuracy: 0.7607\n",
      "FL - Loss: 0.4343, Accuracy: 0.8116\n",
      "GA - Loss: 0.4190, Accuracy: 0.8242\n",
      "HI - Loss: 0.4775, Accuracy: 0.7747\n",
      "ID - Loss: 0.4191, Accuracy: 0.8203\n",
      "IL - Loss: 0.4718, Accuracy: 0.7831\n",
      "IN - Loss: 0.4523, Accuracy: 0.7970\n",
      "IA - Loss: 0.4697, Accuracy: 0.7839\n",
      "KS - Loss: 0.3813, Accuracy: 0.8470\n",
      "KY - Loss: 0.5585, Accuracy: 0.7199\n",
      "LA - Loss: 0.5792, Accuracy: 0.7062\n",
      "ME - Loss: 0.4529, Accuracy: 0.7969\n",
      "MD - Loss: 0.5083, Accuracy: 0.7716\n",
      "MA - Loss: 0.5438, Accuracy: 0.7487\n",
      "MI - Loss: 0.5185, Accuracy: 0.7522\n",
      "MN - Loss: 0.5250, Accuracy: 0.7536\n",
      "MS - Loss: 0.4507, Accuracy: 0.8028\n",
      "MO - Loss: 0.4199, Accuracy: 0.8179\n",
      "MT - Loss: 0.5195, Accuracy: 0.7585\n",
      "NE - Loss: 0.3902, Accuracy: 0.8404\n",
      "NV - Loss: 0.4784, Accuracy: 0.7843\n",
      "NH - Loss: 0.4341, Accuracy: 0.8063\n",
      "NJ - Loss: 0.4521, Accuracy: 0.8036\n",
      "NM - Loss: 0.6662, Accuracy: 0.6490\n",
      "NY - Loss: 0.6145, Accuracy: 0.6972\n",
      "NC - Loss: 0.4204, Accuracy: 0.8215\n",
      "ND - Loss: 0.4261, Accuracy: 0.8115\n",
      "OH - Loss: 0.4905, Accuracy: 0.7668\n",
      "OK - Loss: 0.4433, Accuracy: 0.8031\n",
      "OR - Loss: 0.5354, Accuracy: 0.7464\n",
      "PA - Loss: 0.4645, Accuracy: 0.7886\n",
      "RI - Loss: 0.4819, Accuracy: 0.7884\n",
      "SC - Loss: 0.4431, Accuracy: 0.8046\n",
      "SD - Loss: 0.4036, Accuracy: 0.8222\n",
      "TN - Loss: 0.4721, Accuracy: 0.7818\n",
      "TX - Loss: 0.4043, Accuracy: 0.8362\n",
      "UT - Loss: 0.3441, Accuracy: 0.8806\n",
      "VT - Loss: 0.5978, Accuracy: 0.7134\n",
      "VA - Loss: 0.3830, Accuracy: 0.8483\n",
      "WA - Loss: 0.5200, Accuracy: 0.7510\n",
      "WV - Loss: 0.5422, Accuracy: 0.7238\n",
      "WI - Loss: 0.4349, Accuracy: 0.8072\n",
      "WY - Loss: 0.3959, Accuracy: 0.8415\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# List of all 50 US state abbreviations\n",
    "\n",
    "# Define a simple neural network model\n",
    "def create_model(input_shape):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=input_shape),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Training parameters\n",
    "global_epochs = 10\n",
    "local_epochs = 1\n",
    "batch_size = 256\n",
    "\n",
    "# Initialize global model\n",
    "input_shape = state_features[states[0]].shape[1:]  # Assuming all states have the same feature shape\n",
    "global_model = create_model(input_shape)\n",
    "\n",
    "# Federated Averaging\n",
    "for epoch in range(global_epochs):\n",
    "    start_time=time.time()\n",
    "    print(f\"Global Epoch {epoch + 1}/{global_epochs}\")\n",
    "    \n",
    "    # Store the weights from each local model\n",
    "    local_weights = []\n",
    "\n",
    "    # Train model on each state's data\n",
    "    for state in states:\n",
    "        # print(f\"Training on state: {state}\")\n",
    "\n",
    "        # Create a local model for each state\n",
    "        local_model = create_model(input_shape)\n",
    "        local_model.set_weights(global_model.get_weights())  # Initialize with global model weights\n",
    "\n",
    "        # Train local model\n",
    "        local_model.fit(\n",
    "            state_features[state], state_labels[state],\n",
    "            epochs=local_epochs, batch_size=batch_size\n",
    "        )\n",
    "\n",
    "        # Append the local weights\n",
    "        local_weights.append(local_model.get_weights())\n",
    "\n",
    "    # Average the weights to get new global weights\n",
    "    new_global_weights = [np.mean([local_weights[j][i] for j in range(len(local_weights))], axis=0)\n",
    "                          for i in range(len(local_weights[0]))]\n",
    "    end_time=time.time()\n",
    "    # print('time:',end_time-start_time)\n",
    "    # Set the new global weights\n",
    "    global_model.set_weights(new_global_weights)\n",
    "    loss,accuracy=global_model.evaluate(all_vaild_features,all_vaild_labels)\n",
    "    print('validation accuray:',accuracy)\n",
    "# Evaluate the global model\n",
    "print(\"\\nEvaluating Global Model\")\n",
    "for state in states:\n",
    "    loss, accuracy = global_model.evaluate(val_features[state], val_labels[state], verbose=0)\n",
    "    print(f\"{state} - Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6052d99501ad0b73",
   "metadata": {},
   "source": [
    "# local and global accuracy, fairness (EOp) of FedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae937d3341d0e99a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T18:31:05.305226Z",
     "start_time": "2024-09-04T18:30:50.806420Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174/174 [==============================] - 0s 455us/step\n",
      "23/23 [==============================] - 0s 518us/step\n",
      "235/235 [==============================] - 0s 446us/step\n",
      "111/111 [==============================] - 0s 449us/step\n",
      "1299/1299 [==============================] - 1s 456us/step\n",
      "166/166 [==============================] - 0s 457us/step\n",
      "106/106 [==============================] - 0s 455us/step\n",
      "27/27 [==============================] - 0s 482us/step\n",
      "669/669 [==============================] - 0s 433us/step\n",
      "354/354 [==============================] - 0s 469us/step\n",
      "44/44 [==============================] - 0s 459us/step\n",
      "56/56 [==============================] - 0s 473us/step\n",
      "402/402 [==============================] - 0s 439us/step\n",
      "229/229 [==============================] - 0s 438us/step\n",
      "96/96 [==============================] - 0s 467us/step\n",
      "96/96 [==============================] - 0s 449us/step\n",
      "161/161 [==============================] - 0s 457us/step\n",
      "159/159 [==============================] - 0s 456us/step\n",
      "43/43 [==============================] - 0s 463us/step\n",
      "169/169 [==============================] - 0s 473us/step\n",
      "207/207 [==============================] - 0s 449us/step\n",
      "334/334 [==============================] - 0s 440us/step\n",
      "154/154 [==============================] - 0s 440us/step\n",
      "111/111 [==============================] - 0s 440us/step\n",
      "210/210 [==============================] - 0s 439us/step\n",
      "33/33 [==============================] - 0s 446us/step\n",
      "60/60 [==============================] - 0s 439us/step\n",
      "96/96 [==============================] - 0s 431us/step\n",
      "40/40 [==============================] - 0s 457us/step\n",
      "259/259 [==============================] - 0s 434us/step\n",
      "73/73 [==============================] - 0s 437us/step\n",
      "634/634 [==============================] - 0s 442us/step\n",
      "349/349 [==============================] - 0s 432us/step\n",
      "22/22 [==============================] - 0s 473us/step\n",
      "387/387 [==============================] - 0s 435us/step\n",
      "140/140 [==============================] - 0s 456us/step\n",
      "134/134 [==============================] - 0s 438us/step\n",
      "414/414 [==============================] - 0s 434us/step\n",
      "32/32 [==============================] - 0s 476us/step\n",
      "176/176 [==============================] - 0s 440us/step\n",
      "27/27 [==============================] - 0s 466us/step\n",
      "240/240 [==============================] - 0s 450us/step\n",
      "928/928 [==============================] - 0s 465us/step\n",
      "109/109 [==============================] - 0s 448us/step\n",
      "20/20 [==============================] - 0s 498us/step\n",
      "258/258 [==============================] - 0s 436us/step\n",
      "228/228 [==============================] - 0s 436us/step\n",
      "67/67 [==============================] - 0s 440us/step\n",
      "175/175 [==============================] - 0s 450us/step\n",
      "18/18 [==============================] - 0s 488us/step\n",
      "10532/10532 [==============================] - 5s 435us/step\n",
      "global EO 0.05726452361870171\n",
      "local EO [0.14420069059389606, 0.16573523416656966, 0.046650083366677364, 0.08746554128844425, 0.042591685051415806, 0.030765159774143125, 0.09545313921049631, 0.02837433032737635, 0.04717428445779248, 0.06278209380890631, 0.04999283785974418, 0.03619870043678902, 0.06104868528874746, 0.05167364808451047, 0.08131429325887146, 0.06764979225963713, 0.07071157137772344, 0.11942668910237114, 0.0732973414617667, 0.08352189736037768, 0.15580919628262208, 0.12562202815405188, 0.07499373234539036, 0.07524222913410594, 0.08211203311595949, 0.09332149825019859, 0.05744637724590557, 0.04162110282935244, 0.18998946200622271, 0.06323958374649585, 0.06494809506286359, 0.08425054522033854, 0.06327808893535142, 0.24138138148750737, 0.09184068931785527, 0.06089207968988586, 0.08361449582625685, 0.07799185326957975, 0.18798686504446577, 0.08062392909111077, 0.20120721351450466, 0.11993541391672696, 0.07064609279841333, 0.03783575164845543, 0.017717745405372187, 0.04604590801921832, 0.11486657307277137, 0.21420737476646967, 0.0990595315532905, 0.22318690027118765]\n",
      "local EO average 0.09173882939116375\n"
     ]
    }
   ],
   "source": [
    "y_val_pred={}\n",
    "local_EO=[]\n",
    "def compute_equal_odd(y_true, y_pred, groups):\n",
    "    white_tpr_1 = np.mean(y_pred[(y_true == 1) & (groups == 0)])\n",
    "    black_tpr_1 = np.mean(y_pred[(y_true == 1) & (groups == 1)])\n",
    "    white_tpr_0 = np.mean((1-y_pred)[(y_true == 0) & (groups == 0)])\n",
    "    black_tpr_0 = np.mean((1-y_pred)[(y_true == 0) & (groups == 1)])\n",
    "    EO=np.sum([abs(white_tpr_1-black_tpr_1),abs(white_tpr_0-black_tpr_0)])\n",
    "    if EO<1.01:\n",
    "        return EO\n",
    "    else:\n",
    "        return 'not defined'\n",
    "    return EO\n",
    "for state in states:\n",
    "    y_val_pred[state]=global_model.predict(val_features[state])\n",
    "    y_val_pred[state]=np.where(y_val_pred[state]<0.5,0,1)\n",
    "    EO=compute_equal_odd(val_labels[state],y_val_pred[state],vali_groups[state])\n",
    "    local_EO.append(EO)\n",
    "all_valid_pred=global_model.predict(all_vaild_features)\n",
    "all_valid_pred=np.where(all_valid_pred<0.5,0,1)\n",
    "global_EO=compute_equal_odd(all_vaild_labels,all_valid_pred,all_valid_groups)\n",
    "print('global EO',global_EO)\n",
    "print('local EO',local_EO)\n",
    "local_EO_avg=np.mean(local_EO)\n",
    "print('local EO average',local_EO_avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5e5c220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10532/10532 [==============================] - 5s 485us/step - loss: 0.4911 - accuracy: 0.7745\n",
      "loss, accuracy: [0.4911182224750519, 0.7744896411895752]\n"
     ]
    }
   ],
   "source": [
    "acc=global_model.evaluate(all_vaild_features,all_vaild_labels)\n",
    "print('loss, accuracy:',acc)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ef7bb01b592f75",
   "metadata": {},
   "source": [
    "# Compute the local statistics for LP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9059f59f37de6ebb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T18:31:05.338315Z",
     "start_time": "2024-09-04T18:31:05.335665Z"
    }
   },
   "outputs": [],
   "source": [
    "states_for_local_fairness = [\n",
    "    \"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\",\n",
    "    \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\",\n",
    "    \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\",\n",
    "    \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\",\n",
    "    \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c1e6e8aa2ce0f97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T18:31:05.392707Z",
     "start_time": "2024-09-04T18:31:05.383814Z"
    }
   },
   "outputs": [],
   "source": [
    "def p_computation(label, sensitive_attribute, y, a):\n",
    "    label=np.reshape(label,(-1,))\n",
    "    N=len(label)\n",
    "    sensitive_attribute=np.reshape(sensitive_attribute,(-1,))# Total number of samples\n",
    "    # Create a boolean mask for where both conditions are met\n",
    "    mask = (label == y) & (sensitive_attribute == a)\n",
    "    # print(mask)\n",
    "    # print(\"Number of matching samples:\", np.sum(mask))\n",
    "    \n",
    "    # Compute the probability\n",
    "    p_y_ac = np.sum(mask) / N\n",
    "    return p_y_ac\n",
    "#community_1\n",
    "S= np.zeros((50,2,2))\n",
    "p = np.zeros(50)\n",
    "l=[]\n",
    "for c,state in enumerate(states):\n",
    "    p[c]=len(val_features[state])/len(all_vaild_features)\n",
    "for c,state in enumerate(states):\n",
    "    for a in range(2):\n",
    "        for y in range(2):\n",
    "            S[c,a,y] =p[c]* p_computation(val_labels[state],vali_groups[state], y, a)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78a06f151e8e0014",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T18:31:13.659177Z",
     "start_time": "2024-09-04T18:31:05.422582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174/174 [==============================] - 0s 458us/step\n",
      "23/23 [==============================] - 0s 491us/step\n",
      "235/235 [==============================] - 0s 449us/step\n",
      "111/111 [==============================] - 0s 452us/step\n",
      "1299/1299 [==============================] - 1s 430us/step\n",
      "166/166 [==============================] - 0s 426us/step\n",
      "106/106 [==============================] - 0s 428us/step\n",
      "27/27 [==============================] - 0s 473us/step\n",
      "669/669 [==============================] - 0s 429us/step\n",
      "354/354 [==============================] - 0s 443us/step\n",
      "44/44 [==============================] - 0s 436us/step\n",
      "56/56 [==============================] - 0s 439us/step\n",
      "402/402 [==============================] - 0s 441us/step\n",
      "229/229 [==============================] - 0s 427us/step\n",
      "96/96 [==============================] - 0s 433us/step\n",
      "96/96 [==============================] - 0s 443us/step\n",
      "161/161 [==============================] - 0s 455us/step\n",
      "159/159 [==============================] - 0s 439us/step\n",
      "43/43 [==============================] - 0s 461us/step\n",
      "169/169 [==============================] - 0s 440us/step\n",
      "207/207 [==============================] - 0s 430us/step\n",
      "334/334 [==============================] - 0s 438us/step\n",
      "154/154 [==============================] - 0s 432us/step\n",
      "111/111 [==============================] - 0s 433us/step\n",
      "210/210 [==============================] - 0s 435us/step\n",
      "33/33 [==============================] - 0s 447us/step\n",
      "60/60 [==============================] - 0s 432us/step\n",
      "96/96 [==============================] - 0s 436us/step\n",
      "40/40 [==============================] - 0s 445us/step\n",
      "259/259 [==============================] - 0s 426us/step\n",
      "73/73 [==============================] - 0s 428us/step\n",
      "634/634 [==============================] - 0s 432us/step\n",
      "349/349 [==============================] - 0s 441us/step\n",
      "22/22 [==============================] - 0s 467us/step\n",
      "387/387 [==============================] - 0s 435us/step\n",
      "140/140 [==============================] - 0s 444us/step\n",
      "134/134 [==============================] - 0s 434us/step\n",
      "414/414 [==============================] - 0s 426us/step\n",
      "32/32 [==============================] - 0s 448us/step\n",
      "176/176 [==============================] - 0s 427us/step\n",
      "27/27 [==============================] - 0s 463us/step\n",
      "240/240 [==============================] - 0s 427us/step\n",
      "928/928 [==============================] - 0s 440us/step\n",
      "109/109 [==============================] - 0s 452us/step\n",
      "20/20 [==============================] - 0s 483us/step\n",
      "258/258 [==============================] - 0s 447us/step\n",
      "228/228 [==============================] - 0s 444us/step\n",
      "67/67 [==============================] - 0s 436us/step\n",
      "175/175 [==============================] - 0s 454us/step\n",
      "18/18 [==============================] - 0s 484us/step\n"
     ]
    }
   ],
   "source": [
    "TP= np.zeros((50,2,2))\n",
    "def compute_TP (y_pred,label, sensitive_attribute, y, a):\n",
    "    y_pred=np.reshape(y_pred,(-1,))\n",
    "    label=np.reshape(label,(-1,))\n",
    "    N=len(y_pred)\n",
    "    sensitive_attribute=np.reshape(sensitive_attribute,(-1,))# Total number of samples\n",
    "    # Create a boolean mask for where both conditions are met\n",
    "    count_1= (y_pred == y) & (label == y) & (sensitive_attribute == a)\n",
    "    count_2 = (label== y) & (sensitive_attribute == a)\n",
    "    # print(sum(count_1),sum(count_2))\n",
    "\n",
    "    \n",
    "    # Compute the probability\n",
    "    TP_y_ac = np.sum(count_1) / np.sum(count_2)\n",
    "    return TP_y_ac\n",
    "\n",
    "for c, state in enumerate(states):\n",
    "    y_pred=global_model.predict(val_features[state])\n",
    "    y_pred=np.where(y_pred<0.5,0,1)\n",
    "    for a in range(2):\n",
    "        for y in range(2):\n",
    "            TP[c,a,y]=compute_TP(y_pred,val_labels[state],vali_groups[state],y,a)\n",
    "# print(TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca12b83f091d5a25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T18:31:13.708073Z",
     "start_time": "2024-09-04T18:31:13.702905Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_alpha(label, sensitive_attribute, y, a):\n",
    "    label=np.reshape(label,(-1,))\n",
    "    N=len(label)\n",
    "    sensitive_attribute=np.reshape(sensitive_attribute,(-1,))# Total number of samples\n",
    "    # Create a boolean mask for where both conditions are met\n",
    "    mask = (label == y) & (sensitive_attribute == a)\n",
    "    # print(mask)\n",
    "    # print(\"Number of matching samples:\", np.sum(mask))\n",
    "    \n",
    "    # Compute the probability\n",
    "    alpha_y_ac = np.sum(mask) / N\n",
    "    return alpha_y_ac\n",
    "alpha_a_y = np.zeros((2,2))\n",
    "for a in range(2):\n",
    "    for y in range(2):\n",
    "        alpha_a_y[a,y]=compute_alpha(all_vaild_labels,all_valid_groups,y,a)\n",
    "# print(alpha_a_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4108092",
   "metadata": {},
   "source": [
    "## Solve the LP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cef269116d7a3977",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T20:21:46.144476Z",
     "start_time": "2024-09-04T20:21:45.621783Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 200) (1, 200) (100, 200) (300, 200)\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import linprog\n",
    "import numpy as np\n",
    "def LP_EO(e_0,e_c):\n",
    "# define the objective function\n",
    "    C=[]\n",
    "    for c in range(50):\n",
    "        for a in range(2):\n",
    "            for y in range(2):\n",
    "                C.append(-S[c,a,y])\n",
    "    #define the global fairness constraints\n",
    "    N=2\n",
    "    K=2\n",
    "    A_1=[]\n",
    "    A_2=[]\n",
    "    for c in range(50):\n",
    "        for a in range(2):\n",
    "            for y in range(2):\n",
    "                if  a==0 and y==0:\n",
    "                    A_1.append(-S[c,a,y]/alpha_a_y[a,y])\n",
    "                    # print(S[c,a,y],alpha_a_y[a,y])\n",
    "                elif  a==1 and y==0:\n",
    "                    A_1.append(S[c,a,y]/alpha_a_y[a,y])\n",
    "    \n",
    "                else:\n",
    "                    A_1.append(0)\n",
    "    \n",
    "    for c in range(50):\n",
    "        for a in range(2):\n",
    "            for y in range(2):\n",
    "                if c==c and a==0 and y==1:\n",
    "                    A_2.append(-S[c,a,y]/alpha_a_y[a,y])\n",
    "                elif c==c and a==1 and y==1:\n",
    "                    A_2.append(S[c,a,y]/alpha_a_y[a,y])\n",
    "                else:\n",
    "                    A_2.append(0)\n",
    "    # define local fairness constraints\n",
    "     # Identity matrix of size 50x50, where each row is a basis vector\n",
    "    A_1=np.reshape(A_1,(1,200))\n",
    "    A_2=np.reshape(A_2,(1,200))\n",
    "    # print(np.shape(A_1),np.shape(A_2))\n",
    "    # To access e_i, you can use basis_vectors[i], e.g., e_0 is basis_vectors[0]\n",
    "    \n",
    "    # Define zero vector in R^50\n",
    "    zero_vec = np.zeros((2,4))\n",
    "    I_vector =np.eye(2)\n",
    "    basis_vectors = np.hstack([I_vector, -I_vector])\n",
    "    \n",
    "    # Construct the matrix\n",
    "    # First row: [e_0, e_1, 0, 0]\n",
    "    rows = []\n",
    "\n",
    "# Construct 50 rows dynamically\n",
    "    for i in range(50):\n",
    "        # Initialize the blocks for this row\n",
    "        row_blocks = []\n",
    "        \n",
    "        for j in range(50):\n",
    "            if i == j:  # Diagonal pattern with identity matrices\n",
    "                row_blocks.append(basis_vectors)\n",
    "            else:  # All other positions are zero matrices\n",
    "                row_blocks.append(zero_vec)\n",
    "        \n",
    "        # Horizontally stack the blocks for the current row\n",
    "        row = np.hstack(row_blocks)\n",
    "        rows.append(row)\n",
    "    \n",
    "    # Combine all rows into a single matrix\n",
    "    A_3 = np.vstack(rows)\n",
    "    # print(A_3)\n",
    "\n",
    "    # Combine rows into a single matrix\n",
    "    # define the property of dervied outcome predictor\n",
    "    def K_ac_compute(a,c):\n",
    "        K_ac=np.zeros((3,2))\n",
    "        l_ac=np.zeros((3,1))\n",
    "        K_ac[0:]=[-1,-1]\n",
    "        K_ac[1:]=[(1-TP[c,a,1]), TP[c,a,0]]\n",
    "        K_ac[2:]=[TP[c,a,1], (1-TP[c,a,0])]\n",
    "        l_ac[0:]=[-1]\n",
    "        l_ac[1:]=[TP[c,a,0]]\n",
    "        l_ac[2:]=[TP[c,a,1]]\n",
    "        return K_ac,l_ac\n",
    "    num_clients = 50\n",
    "    block_rows = 3\n",
    "    block_cols = 2\n",
    "    # Define the submatrices k_01, k_11, k_02, k_12 as 3x2 matrices\n",
    "    M = np.zeros((300,200))\n",
    "    l = np.zeros((300, 1))\n",
    "    \n",
    "    # Construct the matrices for all clients\n",
    "    for c in range(num_clients):\n",
    "        for a in range(2):\n",
    "            # Compute submatrices for client c and attribute a\n",
    "            K_ac, l_ac = K_ac_compute(a, c)\n",
    "            \n",
    "            # Calculate starting positions for placing K_ac in M\n",
    "            start_row = (2 * c + a) * block_rows\n",
    "            start_col = (2 * c + a) * block_cols\n",
    "            \n",
    "            # Place K_ac and l_ac in the appropriate block of M and l\n",
    "            M[start_row:start_row + block_rows, start_col:start_col + block_cols] = K_ac\n",
    "            l[start_row:start_row + block_rows] = l_ac\n",
    "    \n",
    "    # Verify the dimensions of the resulting matrix and vector\n",
    "    # print(\"Shape of matrix M:\", M.shape)\n",
    "    # print(\"Shape of vector l:\", l.shape)\n",
    "    # print(np.shape(A_1),np.shape(A_2),np.shape(A_3),np.shape(M))\n",
    "    # combine the constraints\n",
    "    print(np.shape(A_1),np.shape(A_2),np.shape(A_3),np.shape(M))\n",
    "    A=np.vstack((A_1,A_2,A_3, -A_1, -A_2, -A_3,M))\n",
    "    # print(A)\n",
    "    b_global=e_0*np.ones((2,1))\n",
    "    b_local=e_c*np.ones((100,1))\n",
    "    # print(b_local)\n",
    "    b=np.vstack((b_global,b_local,b_global,b_local,l))\n",
    "    # print(b)\n",
    "    res = linprog(C, A_ub=A, b_ub=b)\n",
    "    x=res.x\n",
    "    x=np.reshape(x,(50,2,2))\n",
    "    # print(x)\n",
    "    # print(res.fun)\n",
    "    return x,res.fun\n",
    "x,fun=LP_EO(0.001,0.001)\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff19a88a1f3861",
   "metadata": {},
   "source": [
    "# Clients solve the LAE and generate fair outcome prediction\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2310a969fda69cb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T19:40:14.152557Z",
     "start_time": "2024-09-04T19:40:08.079377Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 456us/step\n",
      "15/15 [==============================] - 0s 467us/step\n",
      "157/157 [==============================] - 0s 434us/step\n",
      " 1/74 [..............................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2278851/2933905974.py:49: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_hat=int(y_pred[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 0s 435us/step\n",
      "866/866 [==============================] - 0s 435us/step\n",
      "111/111 [==============================] - 0s 449us/step\n",
      "71/71 [==============================] - 0s 437us/step\n",
      "18/18 [==============================] - 0s 471us/step\n",
      "446/446 [==============================] - 0s 428us/step\n",
      "236/236 [==============================] - 0s 424us/step\n",
      "30/30 [==============================] - 0s 446us/step\n",
      "38/38 [==============================] - 0s 439us/step\n",
      "268/268 [==============================] - 0s 426us/step\n",
      "153/153 [==============================] - 0s 445us/step\n",
      "65/65 [==============================] - 0s 434us/step\n",
      "65/65 [==============================] - 0s 434us/step\n",
      "108/108 [==============================] - 0s 461us/step\n",
      "106/106 [==============================] - 0s 449us/step\n",
      "29/29 [==============================] - 0s 464us/step\n",
      "113/113 [==============================] - 0s 469us/step\n",
      "138/138 [==============================] - 0s 443us/step\n",
      "223/223 [==============================] - 0s 428us/step\n",
      "103/103 [==============================] - 0s 428us/step\n",
      "74/74 [==============================] - 0s 431us/step\n",
      "140/140 [==============================] - 0s 440us/step\n",
      "22/22 [==============================] - 0s 461us/step\n",
      "40/40 [==============================] - 0s 438us/step\n",
      "64/64 [==============================] - 0s 436us/step\n",
      "27/27 [==============================] - 0s 452us/step\n",
      "173/173 [==============================] - 0s 429us/step\n",
      "49/49 [==============================] - 0s 446us/step\n",
      "423/423 [==============================] - 0s 425us/step\n",
      "233/233 [==============================] - 0s 430us/step\n",
      "15/15 [==============================] - 0s 476us/step\n",
      "258/258 [==============================] - 0s 430us/step\n",
      "93/93 [==============================] - 0s 426us/step\n",
      "90/90 [==============================] - 0s 428us/step\n",
      "276/276 [==============================] - 0s 422us/step\n",
      "21/21 [==============================] - 0s 461us/step\n",
      "117/117 [==============================] - 0s 440us/step\n",
      "18/18 [==============================] - 0s 468us/step\n",
      "160/160 [==============================] - 0s 446us/step\n",
      "619/619 [==============================] - 0s 433us/step\n",
      "73/73 [==============================] - 0s 441us/step\n",
      "13/13 [==============================] - 0s 489us/step\n",
      "172/172 [==============================] - 0s 446us/step\n",
      "152/152 [==============================] - 0s 439us/step\n",
      "45/45 [==============================] - 0s 441us/step\n",
      "117/117 [==============================] - 0s 427us/step\n",
      "12/12 [==============================] - 0s 488us/step\n"
     ]
    }
   ],
   "source": [
    "beta=np.zeros((50,2,3))\n",
    "for a in range(2):\n",
    "        for c in range(50):\n",
    "            A=np.array([[1,1,1],[TP[c,a,0],1,0],[TP[c,a,1],0,1]])\n",
    "            b=np.array([1,x[c,a,0],x[c,a,1]])\n",
    "            beta_ac=np.linalg.solve(A,b)\n",
    "            beta[c,a,:]=beta_ac\n",
    "\n",
    "def compute_tilde_Y(c,a, Y_hat, y_values):\n",
    "    \"\"\"\n",
    "    Compute \\widetilde{Y}_{\\boldsymbol{\\beta}_{ac}}(x,a,c) based on given probabilities.\n",
    "\n",
    "    Parameters:\n",
    "    - beta_ac: Dictionary with keys 'beta_0' and 'beta_y' for probabilities.\n",
    "    - Y_hat: The predicted value \\hat{Y}(x,a,c).\n",
    "    - y_values: List or array of possible y values in \\mathcal{Y}.\n",
    "\n",
    "    Returns:\n",
    "    - tilde_Y: The computed value of \\widetilde{Y}.\n",
    "    \"\"\"\n",
    "    # Extract probabilities\n",
    "    beta_0 = beta[c, a, 0]  # Probability for Y_hat\n",
    "    beta_y = beta[c, a, 1:] \n",
    "    # Probabilities for other y in \\mathcal{Y}\n",
    "    \n",
    "    # Normalize probabilities\n",
    "    \n",
    "    # Generate a random number\n",
    "    rand_val = np.random.rand()\n",
    "    \n",
    "    # Determine the output based on random value\n",
    "    if rand_val < beta_0:\n",
    "        return Y_hat\n",
    "    else:\n",
    "        cumulative_prob = beta_0\n",
    "        for y in y_values:\n",
    "            cumulative_prob += beta_y[y]\n",
    "            if rand_val < cumulative_prob:\n",
    "                return y\n",
    "y_tilde_list = [[] for _ in range(50)] \n",
    "# Example usage\n",
    "for c, state in enumerate(states):\n",
    "    client_features = test_features[state]\n",
    "    client_sensitive = test_groups[state]\n",
    "    y_pred=global_model.predict(test_features[state])\n",
    "    y_pred=np.where(y_pred<0.5,0,1)\n",
    "    for i in range (len(y_pred)):\n",
    "        a=int(client_sensitive[i])\n",
    "        y_hat=int(y_pred[i])\n",
    "        y_tilde=compute_tilde_Y(c,a,y_hat,[0,1])\n",
    "        y_tilde=int(y_tilde)\n",
    "        y_tilde_list[c].append(y_tilde)\n",
    "# print(y_tilde_list[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93273c2",
   "metadata": {},
   "source": [
    "## Fairness and Accuracy after post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "223403d0e9dcdfbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T19:40:31.646239Z",
     "start_time": "2024-09-04T19:40:31.601599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local post EO [0.03475241120389316, 0.0547033755201804, 0.03738355548427974, 0.11791907533687468, 0.008848322132528064, 0.020345774168932185, 0.010696935945617325, 0.07252347680702115, 0.045514527062299415, 0.046641958610895984, 0.12033356117566646, 0.0, 0.048202182654224324, 0.0285040207621865, 0.20663609111374032, 0.0285434543949241, 0.04979720664728432, 0.01542157925832821, 0.014646048292734788, 0.00733496965554381, 0.03335026982304909, 0.016632324595616643, 0.09075465250852283, 0.06184355845991141, 0.06076061065973612, 0.07538827049144259, 0.004750922561407869, 0.08793853986131772, 0.16211377828237775, 0.02868815370990835, 0.027059552559182465, 0.014292969890505935, 0.030861891567245836, 0.0, 0.027132548739157658, 0.014362815026153164, 0.08303074703613395, 0.03025170683448508, 0.1225062392990443, 0.02279535852397252, 0.002673796791443861, 0.08926586672998454, 0.03488968490838551, 0.0, 0.06365145898278429, 0.05169183952667389, 0.05718776448178958, 0.0030963302752293814, 0.011354617978092563, 0.0]\n",
      "local EO 0.04554149592661419\n",
      "global EO 0.003342479604087567\n",
      "accuracy 0.7550355582059795\n"
     ]
    }
   ],
   "source": [
    "local_post_EO=[]\n",
    "for c,state in enumerate(states):\n",
    "    y_post=y_tilde_list[c]\n",
    "    y_post=np.reshape(y_post,(-1,))\n",
    "    y_true=test_labels[state]\n",
    "    y_group=test_groups[state]\n",
    "    dis=compute_equal_odd(y_true,y_post,y_group)\n",
    "    local_post_EO.append(dis)\n",
    "print('local post EO',local_post_EO)\n",
    "local_EO=np.mean(local_post_EO)\n",
    "print('local EO',local_EO)\n",
    "y_tilde_list = np.concatenate(y_tilde_list)  \n",
    "\n",
    "post_EO=compute_equal_odd(all_test_labels,y_tilde_list,all_test_groups)\n",
    "print('global EO', post_EO)\n",
    "#compute accuracy\n",
    "count=np.where(y_tilde_list==all_test_labels,1,0)\n",
    "accuracy=np.sum(count)/len(count)\n",
    "print('accuracy',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9279441a",
   "metadata": {},
   "source": [
    "## Print the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbf10d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before post processing\n",
      "local equal opportunity 0.09173882939116375\n",
      "global equal opportunity 0.05726452361870171\n",
      "accuracy [0.4911182224750519, 0.7744896411895752]\n",
      "after post processing\n",
      "local equal opportunity 0.04554149592661419\n",
      "global equal opportunity 0.003342479604087567\n",
      "accuracy 0.7550355582059795\n"
     ]
    }
   ],
   "source": [
    "print('before post processing')\n",
    "print('local equal opportunity',local_EO_avg)\n",
    "print('global equal opportunity',global_EO)\n",
    "print('accuracy',acc)\n",
    "print('after post processing')\n",
    "print('local equal opportunity',local_EO)\n",
    "print('global equal opportunity',post_EO)\n",
    "print('accuracy',accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
