{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-27 14:43:58.524633: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-27 14:43:58.547479: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-27 14:43:58.547499: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-27 14:43:58.547516: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-27 14:43:58.552254: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-27 14:43:58.552642: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-27 14:43:59.202587: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.src.metrics import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folktables import ACSDataSource, ACSPublicCoverage\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AL (18525, 19) (18525,) (18525,)\n",
      "AK (2377, 19) (2377,) (2377,)\n",
      "AZ (24988, 19) (24988,) (24988,)\n",
      "AR (11838, 19) (11838,) (11838,)\n",
      "CA (138554, 19) (138554,) (138554,)\n",
      "CO (17630, 19) (17630,) (17630,)\n",
      "CT (11204, 19) (11204,) (11204,)\n",
      "DE (2871, 19) (2871,) (2871,)\n",
      "FL (71297, 19) (71297,) (71297,)\n",
      "GA (37701, 19) (37701,) (37701,)\n",
      "HI (4660, 19) (4660,) (4660,)\n",
      "ID (5937, 19) (5937,) (5937,)\n",
      "IL (42827, 19) (42827,) (42827,)\n",
      "IN (24330, 19) (24330,) (24330,)\n",
      "IA (10241, 19) (10241,) (10241,)\n",
      "KS (10242, 19) (10242,) (10242,)\n",
      "KY (17166, 19) (17166,) (17166,)\n",
      "LA (16879, 19) (16879,) (16879,)\n",
      "ME (4513, 19) (4513,) (4513,)\n",
      "MD (18025, 19) (18025,) (18025,)\n",
      "MA (21992, 19) (21992,) (21992,)\n",
      "MI (35624, 19) (35624,) (35624,)\n",
      "MN (16357, 19) (16357,) (16357,)\n",
      "MS (11831, 19) (11831,) (11831,)\n",
      "MO (22327, 19) (22327,) (22327,)\n",
      "MT (3519, 19) (3519,) (3519,)\n",
      "NE (6332, 19) (6332,) (6332,)\n",
      "NV (10201, 19) (10201,) (10201,)\n",
      "NH (4251, 19) (4251,) (4251,)\n",
      "NJ (27609, 19) (27609,) (27609,)\n",
      "NM (7693, 19) (7693,) (7693,)\n",
      "NY (67551, 19) (67551,) (67551,)\n",
      "NC (37181, 19) (37181,) (37181,)\n",
      "ND (2263, 19) (2263,) (2263,)\n",
      "OH (41191, 19) (41191,) (41191,)\n",
      "OK (14851, 19) (14851,) (14851,)\n",
      "OR (14252, 19) (14252,) (14252,)\n",
      "PA (44081, 19) (44081,) (44081,)\n",
      "RI (3325, 19) (3325,) (3325,)\n",
      "SC (18693, 19) (18693,) (18693,)\n",
      "SD (2852, 19) (2852,) (2852,)\n",
      "TN (25497, 19) (25497,) (25497,)\n",
      "TX (98928, 19) (98928,) (98928,)\n",
      "UT (11584, 19) (11584,) (11584,)\n",
      "VT (2069, 19) (2069,) (2069,)\n",
      "VA (27518, 19) (27518,) (27518,)\n",
      "WA (24312, 19) (24312,) (24312,)\n",
      "WV (7136, 19) (7136,) (7136,)\n",
      "WI (18653, 19) (18653,) (18653,)\n",
      "WY (1896, 19) (1896,) (1896,)\n"
     ]
    }
   ],
   "source": [
    "# List of all 50 US state abbreviations\n",
    "states = [\n",
    "    \"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\",\n",
    "    \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\",\n",
    "    \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\",\n",
    "    \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\",\n",
    "    \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"\n",
    "]\n",
    "\n",
    "# Dictionary to store data, features, and labels for each state\n",
    "state_data = {}\n",
    "state_features = {}\n",
    "state_labels = {}\n",
    "state_groups = {}\n",
    "\n",
    "# Assuming `data_source` and `ACSIncome` are already defined\n",
    "for state in states:\n",
    "    # Load data for each state\n",
    "    state_data[state] = data_source.get_data(states=[state], download=True)\n",
    "    # Convert to features and labels\n",
    "    state_features[state], state_labels[state], state_groups[state]= ACSPublicCoverage.df_to_numpy(state_data[state])\n",
    "    state_features[state] = scaler.fit_transform(state_features[state])\n",
    "    state_groups[state] = np.where(state_groups[state] == 1, 0, 1)\n",
    "    print(state, state_features[state].shape, state_labels[state].shape,state_groups[state].shape)\n",
    "\n",
    "# Example usage: Access data, features, and labels for California (CA)\n",
    "ca_features = state_features[\"CA\"]\n",
    "ca_labels = state_labels[\"CA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AL: Train: (9262, 19), Val: (5557, 19), Test: (3706, 19)\n",
      "AK: Train: (1188, 19), Val: (713, 19), Test: (476, 19)\n",
      "AZ: Train: (12494, 19), Val: (7496, 19), Test: (4998, 19)\n",
      "AR: Train: (5919, 19), Val: (3551, 19), Test: (2368, 19)\n",
      "CA: Train: (69277, 19), Val: (41566, 19), Test: (27711, 19)\n",
      "CO: Train: (8815, 19), Val: (5289, 19), Test: (3526, 19)\n",
      "CT: Train: (5602, 19), Val: (3361, 19), Test: (2241, 19)\n",
      "DE: Train: (1435, 19), Val: (861, 19), Test: (575, 19)\n",
      "FL: Train: (35648, 19), Val: (21389, 19), Test: (14260, 19)\n",
      "GA: Train: (18850, 19), Val: (11310, 19), Test: (7541, 19)\n",
      "HI: Train: (2330, 19), Val: (1398, 19), Test: (932, 19)\n",
      "ID: Train: (2968, 19), Val: (1781, 19), Test: (1188, 19)\n",
      "IL: Train: (21413, 19), Val: (12848, 19), Test: (8566, 19)\n",
      "IN: Train: (12165, 19), Val: (7299, 19), Test: (4866, 19)\n",
      "IA: Train: (5120, 19), Val: (3072, 19), Test: (2049, 19)\n",
      "KS: Train: (5121, 19), Val: (3072, 19), Test: (2049, 19)\n",
      "KY: Train: (8583, 19), Val: (5149, 19), Test: (3434, 19)\n",
      "LA: Train: (8439, 19), Val: (5064, 19), Test: (3376, 19)\n",
      "ME: Train: (2256, 19), Val: (1354, 19), Test: (903, 19)\n",
      "MD: Train: (9012, 19), Val: (5407, 19), Test: (3606, 19)\n",
      "MA: Train: (10996, 19), Val: (6597, 19), Test: (4399, 19)\n",
      "MI: Train: (17812, 19), Val: (10687, 19), Test: (7125, 19)\n",
      "MN: Train: (8178, 19), Val: (4907, 19), Test: (3272, 19)\n",
      "MS: Train: (5915, 19), Val: (3549, 19), Test: (2367, 19)\n",
      "MO: Train: (11163, 19), Val: (6698, 19), Test: (4466, 19)\n",
      "MT: Train: (1759, 19), Val: (1056, 19), Test: (704, 19)\n",
      "NE: Train: (3166, 19), Val: (1899, 19), Test: (1267, 19)\n",
      "NV: Train: (5100, 19), Val: (3060, 19), Test: (2041, 19)\n",
      "NH: Train: (2125, 19), Val: (1275, 19), Test: (851, 19)\n",
      "NJ: Train: (13804, 19), Val: (8283, 19), Test: (5522, 19)\n",
      "NM: Train: (3846, 19), Val: (2308, 19), Test: (1539, 19)\n",
      "NY: Train: (33775, 19), Val: (20265, 19), Test: (13511, 19)\n",
      "NC: Train: (18590, 19), Val: (11154, 19), Test: (7437, 19)\n",
      "ND: Train: (1131, 19), Val: (679, 19), Test: (453, 19)\n",
      "OH: Train: (20595, 19), Val: (12357, 19), Test: (8239, 19)\n",
      "OK: Train: (7425, 19), Val: (4455, 19), Test: (2971, 19)\n",
      "OR: Train: (7126, 19), Val: (4275, 19), Test: (2851, 19)\n",
      "PA: Train: (22040, 19), Val: (13224, 19), Test: (8817, 19)\n",
      "RI: Train: (1662, 19), Val: (997, 19), Test: (666, 19)\n",
      "SC: Train: (9346, 19), Val: (5608, 19), Test: (3739, 19)\n",
      "SD: Train: (1426, 19), Val: (855, 19), Test: (571, 19)\n",
      "TN: Train: (12748, 19), Val: (7649, 19), Test: (5100, 19)\n",
      "TX: Train: (49464, 19), Val: (29678, 19), Test: (19786, 19)\n",
      "UT: Train: (5792, 19), Val: (3475, 19), Test: (2317, 19)\n",
      "VT: Train: (1034, 19), Val: (621, 19), Test: (414, 19)\n",
      "VA: Train: (13759, 19), Val: (8255, 19), Test: (5504, 19)\n",
      "WA: Train: (12156, 19), Val: (7293, 19), Test: (4863, 19)\n",
      "WV: Train: (3568, 19), Val: (2140, 19), Test: (1428, 19)\n",
      "WI: Train: (9326, 19), Val: (5596, 19), Test: (3731, 19)\n",
      "WY: Train: (948, 19), Val: (568, 19), Test: (380, 19)\n",
      "Total vali Features: (337000, 19), Total Test Labels: (337000,), Total Test Groups: (337000,)\n",
      "Total Test Features: (224702, 19), Total Test Labels: (224702,), Total Test Groups: (224702,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Define dictionaries to store train, validation, and test data for each state\n",
    "train_features = {}\n",
    "train_labels = {}\n",
    "train_groups = {}\n",
    "val_features = {}\n",
    "val_labels = {}\n",
    "vali_groups = {}\n",
    "test_features = {}\n",
    "test_labels = {}\n",
    "test_groups = {}\n",
    "all_test_features = []\n",
    "all_test_labels = []\n",
    "all_test_groups = []\n",
    "all_vaild_features = []\n",
    "all_valid_labels = []\n",
    "all_valid_groups = []\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Split ratio configuration\n",
    "train_ratio = 0.5\n",
    "val_ratio = 0.3\n",
    "test_ratio = 0.2\n",
    "\n",
    "for state in states:\n",
    "    # Get the features and labels for the state\n",
    "    features = state_features[state]\n",
    "    labels = state_labels[state]\n",
    "    groups = state_groups[state]\n",
    "\n",
    "    # First split into train and temp (validation + test) sets\n",
    "    X_train, X_temp, y_train, y_temp, s_train, s_temp = train_test_split(\n",
    "        features, labels, groups, test_size=(1 - train_ratio), random_state=42)\n",
    "\n",
    "    # Then split the temp set into validation and test sets\n",
    "    X_val, X_test, y_val, y_test, s_val, s_test = train_test_split(\n",
    "        X_temp, y_temp, s_temp, test_size=(test_ratio / (val_ratio + test_ratio)), random_state=42)\n",
    "\n",
    "    # Store the splits into respective dictionaries\n",
    "    train_features[state] = X_train\n",
    "    train_labels[state] = y_train\n",
    "    train_groups[state] = s_train\n",
    "    val_features[state] = X_val\n",
    "    val_labels[state] = y_val\n",
    "    vali_groups[state] = s_val\n",
    "    test_features[state] = X_test\n",
    "    test_labels[state] = y_test\n",
    "    test_groups[state] = s_test\n",
    "    all_vaild_features.append(X_val)\n",
    "    all_valid_labels.append(y_val)\n",
    "    all_valid_groups.append(s_val)\n",
    "    all_test_features.append(X_test)\n",
    "    all_test_labels.append(y_test)\n",
    "    all_test_groups.append(s_test)\n",
    "\n",
    "    # Print the shapes for verification\n",
    "    print(f\"{state}: Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n",
    "all_test_features = np.concatenate(all_test_features)\n",
    "all_test_labels = np.concatenate(all_test_labels)\n",
    "all_test_groups = np.concatenate(all_test_groups)\n",
    "all_vaild_features=np.concatenate(all_vaild_features)\n",
    "all_vaild_labels=np.concatenate(all_valid_labels)\n",
    "all_valid_groups=np.concatenate(all_valid_groups)\n",
    "print(\n",
    "    f\"Total vali Features: {all_vaild_features.shape}, Total Test Labels: {all_vaild_labels.shape}, Total Test Groups: {all_valid_groups.shape}\")\n",
    "print(\n",
    "    f\"Total Test Features: {all_test_features.shape}, Total Test Labels: {all_test_labels.shape}, Total Test Groups: {all_test_groups.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-27 14:44:34.131511: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-27 14:44:34.147639: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "def create_model(input_shape):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=input_shape),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "input_shape = state_features[states[0]].shape[1:]  # Assuming all states have the same feature shape\n",
    "global_model = create_model(input_shape)\n",
    "global_model.load_weights('FedAvg.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred={}\n",
    "local_EO=[]\n",
    "def compute_equal_odd(y_true, y_pred, groups):\n",
    "    white_tpr_1 = np.mean(y_pred[(y_true == 1) & (groups == 0)])\n",
    "    black_tpr_1 = np.mean(y_pred[(y_true == 1) & (groups == 1)])\n",
    "    white_tpr_0 = np.mean((1-y_pred)[(y_true == 0) & (groups == 0)])\n",
    "    black_tpr_0 = np.mean((1-y_pred)[(y_true == 0) & (groups == 1)])\n",
    "    EO=np.sum([abs(white_tpr_1-black_tpr_1),abs(white_tpr_0-black_tpr_0)])\n",
    "    if EO<1.01:\n",
    "        return EO\n",
    "    else:\n",
    "        return 'not defined'\n",
    "    return EO\n",
    "def compute_equal_opp(y_true, y_pred, groups):\n",
    "    y_true = np.asarray(y_true).flatten()\n",
    "    y_pred = np.asarray(y_pred).flatten()\n",
    "    groups = np.asarray(groups).flatten()\n",
    "    white_tpr_1 = np.mean(y_pred[(y_true == 1) & (groups == 1)])\n",
    "    black_tpr_1 = np.mean(y_pred[(y_true == 1) & (groups == 0)])\n",
    "    EOp=abs(white_tpr_1-black_tpr_1)\n",
    "    return EOp\n",
    "# for state in states:\n",
    "#     y_val_pred[state]=global_model.predict(val_features[state])\n",
    "#     y_val_pred[state]=np.where(y_val_pred[state]<0.5,0,1)\n",
    "#     EO=compute_equal_odd(val_labels[state],y_val_pred[state],vali_groups[state])\n",
    "#     local_EO.append(EO)\n",
    "# all_valid_pred=global_model.predict(all_vaild_features)\n",
    "# all_valid_pred=np.where(all_valid_pred<0.5,0,1)\n",
    "# global_EO=compute_equal_odd(all_vaild_labels,all_valid_pred,all_valid_groups)\n",
    "# print('global EO',global_EO)\n",
    "# print('local EO',local_EO)\n",
    "# local_EO_avg=np.mean(local_EO) \n",
    "# print('local EO avg',local_EO_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10532/10532 [==============================] - 5s 442us/step\n",
      "global_EO 0.03155481533960125\n",
      "local_EO [0.07696981225833499, 0.032296971321361556, 0.01980102695763797, 0.05406850459482043, 0.04551624393135362, 0.024518781945459645, 0.08850499078448126, 0.011798839458413923, 0.010992717704885746, 0.01516835890214685, 0.04195497514862101, 0.030682856769813305, 0.027924824654384506, 0.00995385720601244, 0.08028083028083027, 0.061002063382889826, 0.04988160033929456, 0.06070372990766271, 0.04401749229335439, 0.032001162492419355, 0.1592111145500189, 0.07236581209989845, 0.0357538802660754, 0.04026351389211302, 0.049694242643487874, 0.15611133521581283, 0.005352755352755367, 0.07009497788186314, 0.268944099378882, 0.04414436859501386, 0.007332352780955453, 0.07493896740770117, 0.01282544308836131, 0.04016337644656226, 0.0332986015903482, 0.014389931056597693, 0.05396825396825394, 0.03349969021424809, 0.192545953082157, 0.010102344658949769, 0.14180672268907563, 0.09135506247921321, 0.04689847626817156, 0.024972811858057775, 0.04090909090909095, 0.026152517081599047, 0.09946425313824092, 0.05122941574554479, 0.03971133448323716, 0.0315040650406504]\n",
      "local_EO_avg 0.055740888083942314\n",
      "acc 0.7782581602373887\n"
     ]
    }
   ],
   "source": [
    "y_val_pred={}\n",
    "local_EO=[]\n",
    "for state in states:\n",
    "    y_val_pred[state]=global_model.predict(val_features[state],verbose=0)\n",
    "    y_val_pred[state]=np.where(y_val_pred[state]<0.5,0,1)\n",
    "    EO=compute_equal_opp(val_labels[state],y_val_pred[state],vali_groups[state])\n",
    "    local_EO.append(EO)\n",
    "all_valid_pred=global_model.predict(all_vaild_features)\n",
    "all_valid_pred=np.where(all_valid_pred<0.5,0,1)\n",
    "global_EO=compute_equal_opp(all_vaild_labels,all_valid_pred,all_valid_groups)\n",
    "print('global_EO',global_EO)\n",
    "print('local_EO',local_EO)\n",
    "local_EO_avg=np.mean(local_EO) \n",
    "print('local_EO_avg',local_EO_avg)\n",
    "all_valid_pred=all_valid_pred.flatten()\n",
    "all_vaild_labels=all_vaild_labels.flatten()\n",
    "acc_count=np.where(all_valid_pred==all_vaild_labels,1,0)\n",
    "acc=np.sum(acc_count)/len(acc_count)\n",
    "print('acc',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# states_for_local_fairness = [\n",
    "#     \"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\",\n",
    "#     \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\",\n",
    "#     \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\",\n",
    "#     \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\",\n",
    "#     \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\"\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "def p_computation(label, sensitive_attribute, y, a):\n",
    "    label=np.reshape(label,(-1,))\n",
    "    N=len(label)\n",
    "    sensitive_attribute=np.reshape(sensitive_attribute,(-1,))# Total number of samples\n",
    "    # Create a boolean mask for where both conditions are met\n",
    "    mask = (label == y) & (sensitive_attribute == a)\n",
    "    # print(mask)\n",
    "    # print(\"Number of matching samples:\", np.sum(mask))\n",
    "    \n",
    "    # Compute the probability\n",
    "    p_y_ac = np.sum(mask) / N\n",
    "    return p_y_ac\n",
    "#community_1\n",
    "S= np.zeros((50,2,2))\n",
    "p = np.zeros(50)\n",
    "l=[]\n",
    "for c,state in enumerate(states):\n",
    "    p[c]=len(val_features[state])/len(all_vaild_features)\n",
    "for c,state in enumerate(states):\n",
    "    for a in range(2):\n",
    "        for y in range(2):\n",
    "            S[c,a,y] =p[c]* p_computation(val_labels[state],vali_groups[state], y, a)\n",
    "print(np.sum(S))    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174/174 [==============================] - 0s 450us/step\n",
      "2615 2911\n",
      "529 907\n",
      "960 1171\n",
      "375 568\n",
      "23/23 [==============================] - 0s 453us/step\n",
      "229 243\n",
      "44 91\n",
      "180 215\n",
      "74 164\n",
      "235/235 [==============================] - 0s 427us/step\n",
      "3527 3755\n",
      "600 1640\n",
      "1207 1341\n",
      "263 760\n",
      "111/111 [==============================] - 0s 446us/step\n",
      "1594 1711\n",
      "502 1050\n",
      "401 448\n",
      "182 342\n",
      "1299/1299 [==============================] - 1s 425us/step\n",
      "14450 15227\n",
      "2502 8328\n",
      "10477 11044\n",
      "1776 6967\n",
      "166/166 [==============================] - 0s 424us/step\n",
      "3136 3281\n",
      "394 1167\n",
      "500 528\n",
      "98 313\n",
      "106/106 [==============================] - 0s 420us/step\n",
      "1625 1687\n",
      "289 699\n",
      "502 538\n",
      "142 437\n",
      "27/27 [==============================] - 0s 458us/step\n",
      "385 408\n",
      "74 188\n",
      "150 155\n",
      "42 110\n",
      "669/669 [==============================] - 0s 417us/step\n",
      "11505 12546\n",
      "1605 3336\n",
      "3615 4118\n",
      "653 1389\n",
      "354/354 [==============================] - 0s 437us/step\n",
      "5026 5511\n",
      "636 1179\n",
      "3033 3487\n",
      "594 1133\n",
      "44/44 [==============================] - 0s 436us/step\n",
      "217 231\n",
      "21 62\n",
      "737 774\n",
      "126 331\n",
      "56/56 [==============================] - 0s 452us/step\n",
      "1153 1252\n",
      "155 333\n",
      "137 150\n",
      "20 46\n",
      "402/402 [==============================] - 0s 429us/step\n",
      "6628 6998\n",
      "1019 2476\n",
      "1885 2077\n",
      "570 1297\n",
      "229/229 [==============================] - 0s 431us/step\n",
      "4148 4459\n",
      "825 1664\n",
      "650 741\n",
      "220 435\n",
      "96/96 [==============================] - 0s 446us/step\n",
      "1855 1954\n",
      "373 819\n",
      "174 187\n",
      "60 112\n",
      "96/96 [==============================] - 0s 429us/step\n",
      "1971 2116\n",
      "253 461\n",
      "326 372\n",
      "60 123\n",
      "161/161 [==============================] - 0s 441us/step\n",
      "2433 2617\n",
      "887 1880\n",
      "321 351\n",
      "127 301\n",
      "159/159 [==============================] - 0s 447us/step\n",
      "1847 1951\n",
      "421 1053\n",
      "883 1009\n",
      "484 1051\n",
      "43/43 [==============================] - 0s 488us/step\n",
      "803 871\n",
      "200 377\n",
      "61 69\n",
      "18 37\n",
      "169/169 [==============================] - 0s 447us/step\n",
      "2121 2231\n",
      "328 769\n",
      "1399 1530\n",
      "346 877\n",
      "207/207 [==============================] - 0s 443us/step\n",
      "3206 3305\n",
      "646 1620\n",
      "921 954\n",
      "172 718\n",
      "334/334 [==============================] - 0s 436us/step\n",
      "5539 5856\n",
      "1194 2833\n",
      "899 1026\n",
      "480 972\n",
      "154/154 [==============================] - 0s 437us/step\n",
      "2784 2921\n",
      "452 1243\n",
      "375 415\n",
      "131 328\n",
      "111/111 [==============================] - 0s 442us/step\n",
      "1319 1435\n",
      "257 451\n",
      "933 1109\n",
      "338 554\n",
      "210/210 [==============================] - 0s 425us/step\n",
      "3988 4400\n",
      "679 1238\n",
      "645 734\n",
      "195 326\n",
      "33/33 [==============================] - 0s 432us/step\n",
      "626 659\n",
      "91 259\n",
      "65 71\n",
      "34 67\n",
      "60/60 [==============================] - 0s 449us/step\n",
      "1238 1325\n",
      "139 308\n",
      "174 192\n",
      "33 74\n",
      "96/96 [==============================] - 0s 444us/step\n",
      "1242 1333\n",
      "235 504\n",
      "798 857\n",
      "145 366\n",
      "40/40 [==============================] - 0s 441us/step\n",
      "804 823\n",
      "151 322\n",
      "89 95\n",
      "7 35\n",
      "259/259 [==============================] - 0s 428us/step\n",
      "3917 4125\n",
      "596 1316\n",
      "1806 1927\n",
      "374 915\n",
      "73/73 [==============================] - 0s 429us/step\n",
      "781 833\n",
      "218 633\n",
      "359 407\n",
      "153 435\n",
      "634/634 [==============================] - 0s 438us/step\n",
      "7780 8171\n",
      "1692 4469\n",
      "3721 3973\n",
      "1109 3652\n",
      "349/349 [==============================] - 0s 428us/step\n",
      "5435 5854\n",
      "808 1548\n",
      "2312 2603\n",
      "585 1149\n",
      "22/22 [==============================] - 0s 441us/step\n",
      "435 460\n",
      "48 113\n",
      "55 67\n",
      "15 39\n",
      "387/387 [==============================] - 0s 416us/step\n",
      "6558 6960\n",
      "1447 3126\n",
      "1065 1221\n",
      "521 1050\n",
      "140/140 [==============================] - 0s 425us/step\n",
      "2093 2357\n",
      "390 693\n",
      "912 1081\n",
      "187 324\n",
      "134/134 [==============================] - 0s 421us/step\n",
      "2147 2265\n",
      "513 1260\n",
      "462 498\n",
      "89 252\n",
      "414/414 [==============================] - 0s 424us/step\n",
      "7450 7846\n",
      "1493 3093\n",
      "1134 1281\n",
      "451 1004\n",
      "32/32 [==============================] - 0s 461us/step\n",
      "532 549\n",
      "108 229\n",
      "126 133\n",
      "24 86\n",
      "176/176 [==============================] - 0s 440us/step\n",
      "2666 2859\n",
      "387 785\n",
      "1142 1318\n",
      "325 646\n",
      "27/27 [==============================] - 0s 445us/step\n",
      "506 537\n",
      "50 112\n",
      "116 138\n",
      "40 68\n",
      "240/240 [==============================] - 0s 413us/step\n",
      "4056 4447\n",
      "755 1619\n",
      "972 1115\n",
      "261 468\n",
      "928/928 [==============================] - 0s 441us/step\n",
      "16506 18027\n",
      "1903 3946\n",
      "5412 6076\n",
      "862 1629\n",
      "109/109 [==============================] - 0s 435us/step\n",
      "2513 2640\n",
      "190 407\n",
      "333 367\n",
      "30 61\n",
      "20/20 [==============================] - 0s 456us/step\n",
      "338 357\n",
      "79 220\n",
      "28 29\n",
      "6 15\n",
      "258/258 [==============================] - 0s 416us/step\n",
      "4297 4576\n",
      "492 952\n",
      "1896 2085\n",
      "315 642\n",
      "228/228 [==============================] - 0s 418us/step\n",
      "3424 3637\n",
      "708 1699\n",
      "1187 1273\n",
      "217 684\n",
      "67/67 [==============================] - 0s 428us/step\n",
      "1087 1178\n",
      "393 806\n",
      "79 101\n",
      "24 55\n",
      "175/175 [==============================] - 0s 437us/step\n",
      "3509 3684\n",
      "499 1173\n",
      "383 438\n",
      "140 301\n",
      "18/18 [==============================] - 0s 478us/step\n",
      "381 404\n",
      "35 82\n",
      "42 58\n",
      "11 24\n",
      "[[[0.89831673 0.58324146]\n",
      "  [0.81981213 0.66021127]]\n",
      "\n",
      " [[0.94238683 0.48351648]\n",
      "  [0.8372093  0.45121951]]\n",
      "\n",
      " [[0.93928096 0.36585366]\n",
      "  [0.90007457 0.34605263]]\n",
      "\n",
      " [[0.93161894 0.47809524]\n",
      "  [0.89508929 0.53216374]]\n",
      "\n",
      " [[0.94897222 0.30043228]\n",
      "  [0.94865991 0.25491603]]\n",
      "\n",
      " [[0.95580616 0.33761782]\n",
      "  [0.9469697  0.31309904]]\n",
      "\n",
      " [[0.96324837 0.41344778]\n",
      "  [0.9330855  0.32494279]]\n",
      "\n",
      " [[0.94362745 0.39361702]\n",
      "  [0.96774194 0.38181818]]\n",
      "\n",
      " [[0.91702535 0.48111511]\n",
      "  [0.87785333 0.47012239]]\n",
      "\n",
      " [[0.91199419 0.5394402 ]\n",
      "  [0.86980212 0.52427184]]\n",
      "\n",
      " [[0.93939394 0.33870968]\n",
      "  [0.95219638 0.38066465]]\n",
      "\n",
      " [[0.92092652 0.46546547]\n",
      "  [0.91333333 0.43478261]]\n",
      "\n",
      " [[0.94712775 0.41155089]\n",
      "  [0.90755898 0.43947571]]\n",
      "\n",
      " [[0.93025342 0.49579327]\n",
      "  [0.87719298 0.50574713]]\n",
      "\n",
      " [[0.9493347  0.45543346]\n",
      "  [0.93048128 0.53571429]]\n",
      "\n",
      " [[0.93147448 0.54880694]\n",
      "  [0.87634409 0.48780488]]\n",
      "\n",
      " [[0.92969049 0.47180851]\n",
      "  [0.91452991 0.42192691]]\n",
      "\n",
      " [[0.946694   0.39981007]\n",
      "  [0.87512389 0.4605138 ]]\n",
      "\n",
      " [[0.92192882 0.53050398]\n",
      "  [0.88405797 0.48648649]]\n",
      "\n",
      " [[0.95069476 0.42652796]\n",
      "  [0.91437908 0.3945268 ]]\n",
      "\n",
      " [[0.97004539 0.39876543]\n",
      "  [0.96540881 0.23955432]]\n",
      "\n",
      " [[0.94586749 0.42146135]\n",
      "  [0.87621832 0.49382716]]\n",
      "\n",
      " [[0.95309825 0.36363636]\n",
      "  [0.90361446 0.39939024]]\n",
      "\n",
      " [[0.91916376 0.56984479]\n",
      "  [0.84129847 0.6101083 ]]\n",
      "\n",
      " [[0.90636364 0.54846527]\n",
      "  [0.87874659 0.59815951]]\n",
      "\n",
      " [[0.94992413 0.35135135]\n",
      "  [0.91549296 0.50746269]]\n",
      "\n",
      " [[0.93433962 0.4512987 ]\n",
      "  [0.90625    0.44594595]]\n",
      "\n",
      " [[0.93173293 0.46626984]\n",
      "  [0.93115519 0.39617486]]\n",
      "\n",
      " [[0.97691373 0.4689441 ]\n",
      "  [0.93684211 0.2       ]]\n",
      "\n",
      " [[0.94957576 0.45288754]\n",
      "  [0.9372081  0.40874317]]\n",
      "\n",
      " [[0.93757503 0.34439179]\n",
      "  [0.88206388 0.35172414]]\n",
      "\n",
      " [[0.95214784 0.37860819]\n",
      "  [0.93657186 0.30366922]]\n",
      "\n",
      " [[0.92842501 0.52196382]\n",
      "  [0.88820592 0.50913838]]\n",
      "\n",
      " [[0.94565217 0.42477876]\n",
      "  [0.82089552 0.38461538]]\n",
      "\n",
      " [[0.94224138 0.46289187]\n",
      "  [0.87223587 0.49619048]]\n",
      "\n",
      " [[0.88799321 0.56277056]\n",
      "  [0.84366327 0.57716049]]\n",
      "\n",
      " [[0.94790287 0.40714286]\n",
      "  [0.92771084 0.3531746 ]]\n",
      "\n",
      " [[0.94952842 0.48270288]\n",
      "  [0.8852459  0.44920319]]\n",
      "\n",
      " [[0.96903461 0.47161572]\n",
      "  [0.94736842 0.27906977]]\n",
      "\n",
      " [[0.93249388 0.49299363]\n",
      "  [0.86646434 0.50309598]]\n",
      "\n",
      " [[0.94227188 0.44642857]\n",
      "  [0.84057971 0.58823529]]\n",
      "\n",
      " [[0.91207556 0.46633725]\n",
      "  [0.87174888 0.55769231]]\n",
      "\n",
      " [[0.91562656 0.48226052]\n",
      "  [0.89071758 0.52915899]]\n",
      "\n",
      " [[0.95189394 0.46683047]\n",
      "  [0.90735695 0.49180328]]\n",
      "\n",
      " [[0.94677871 0.35909091]\n",
      "  [0.96551724 0.4       ]]\n",
      "\n",
      " [[0.93902972 0.51680672]\n",
      "  [0.90935252 0.49065421]]\n",
      "\n",
      " [[0.94143525 0.41671572]\n",
      "  [0.93244305 0.31725146]]\n",
      "\n",
      " [[0.92275042 0.48759305]\n",
      "  [0.78217822 0.43636364]]\n",
      "\n",
      " [[0.95249729 0.42540494]\n",
      "  [0.87442922 0.46511628]]\n",
      "\n",
      " [[0.94306931 0.42682927]\n",
      "  [0.72413793 0.45833333]]]\n"
     ]
    }
   ],
   "source": [
    "TP= np.zeros((50,2,2))\n",
    "def compute_TP (y_pred,label, sensitive_attribute, y, a):\n",
    "    y_pred=np.reshape(y_pred,(-1,))\n",
    "    label=np.reshape(label,(-1,))\n",
    "    N=len(y_pred)\n",
    "    sensitive_attribute=np.reshape(sensitive_attribute,(-1,))# Total number of samples\n",
    "    # Create a boolean mask for where both conditions are met\n",
    "    count_1= (y_pred == y) & (label == y) & (sensitive_attribute == a)\n",
    "    count_2 = (label== y) & (sensitive_attribute == a)\n",
    "    print(sum(count_1),sum(count_2))\n",
    "\n",
    "    \n",
    "    # Compute the probability\n",
    "    TP_y_ac = np.sum(count_1) / np.sum(count_2)\n",
    "    return TP_y_ac\n",
    "\n",
    "for c, state in enumerate(states):\n",
    "    y_pred=global_model.predict(val_features[state])\n",
    "    y_pred=np.where(y_pred<0.5,0,1)\n",
    "    for a in range(2):\n",
    "        for y in range(2):\n",
    "            TP[c,a,y]=compute_TP(y_pred,val_labels[state],vali_groups[state],y,a)\n",
    "print(TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.52161128 0.19447478]\n",
      " [0.18381899 0.10009496]]\n"
     ]
    }
   ],
   "source": [
    "def compute_alpha(label, sensitive_attribute, y, a):\n",
    "    label=np.reshape(label,(-1,))\n",
    "    N=len(label)\n",
    "    sensitive_attribute=np.reshape(sensitive_attribute,(-1,))# Total number of samples\n",
    "    # Create a boolean mask for where both conditions are met\n",
    "    mask = (label == y) & (sensitive_attribute == a)\n",
    "    # print(mask)\n",
    "    # print(\"Number of matching samples:\", np.sum(mask))\n",
    "    \n",
    "    # Compute the probability\n",
    "    alpha_y_ac = np.sum(mask) / N\n",
    "    return alpha_y_ac\n",
    "alpha_a_y = np.zeros((2,2))\n",
    "for a in range(2):\n",
    "    for y in range(2):\n",
    "        alpha_a_y[a,y]=compute_alpha(all_vaild_labels,all_valid_groups,y,a)\n",
    "print(alpha_a_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import linprog\n",
    "import numpy as np\n",
    "def LP_EO(e_0,e_c):\n",
    "# define the objective function\n",
    "    C=[]\n",
    "    for c in range(50):\n",
    "        for a in range(2):\n",
    "            for y in range(2):\n",
    "                C.append(-S[c,a,y])\n",
    "    #define the global fairness constraints\n",
    "    N=2\n",
    "    K=2\n",
    "    A_1=[]\n",
    "    A_2=[]\n",
    "    for c in range(50):\n",
    "        for a in range(2):\n",
    "            for y in range(2):\n",
    "                if  a==0 and y==0:\n",
    "                    A_1.append(-S[c,a,y]/alpha_a_y[a,y])\n",
    "                    # print(S[c,a,y],alpha_a_y[a,y])\n",
    "                elif  a==1 and y==0:\n",
    "                    A_1.append(S[c,a,y]/alpha_a_y[a,y])\n",
    "    \n",
    "                else:\n",
    "                    A_1.append(0)\n",
    "    \n",
    "    for c in range(50):\n",
    "        for a in range(2):\n",
    "            for y in range(2):\n",
    "                if c==c and a==0 and y==1:\n",
    "                    A_2.append(-S[c,a,y]/alpha_a_y[a,y])\n",
    "                elif c==c and a==1 and y==1:\n",
    "                    A_2.append(S[c,a,y]/alpha_a_y[a,y])\n",
    "                else:\n",
    "                    A_2.append(0)\n",
    "    # define local fairness constraints\n",
    "     # Identity matrix of size 50x50, where each row is a basis vector\n",
    "    A_1=np.reshape(A_1,(1,200))\n",
    "    A_2=np.reshape(A_2,(1,200))\n",
    "    # print(np.shape(A_1),np.shape(A_2))\n",
    "    # To access e_i, you can use basis_vectors[i], e.g., e_0 is basis_vectors[0]\n",
    "    \n",
    "    # Define zero vector in R^50\n",
    "    zero_vec = np.zeros((2,4))\n",
    "    I_vector =np.eye(2)\n",
    "    basis_vectors = np.hstack([I_vector, -I_vector])\n",
    "    \n",
    "    # Construct the matrix\n",
    "    # First row: [e_0, e_1, 0, 0]\n",
    "    rows = []\n",
    "\n",
    "# Construct 50 rows dynamically\n",
    "    for i in range(50):\n",
    "        # Initialize the blocks for this row\n",
    "        row_blocks = []\n",
    "        \n",
    "        for j in range(50):\n",
    "            if i == j:  # Diagonal pattern with identity matrices\n",
    "                row_blocks.append(basis_vectors)\n",
    "            else:  # All other positions are zero matrices\n",
    "                row_blocks.append(zero_vec)\n",
    "        \n",
    "        # Horizontally stack the blocks for the current row\n",
    "        row = np.hstack(row_blocks)\n",
    "        rows.append(row)\n",
    "    \n",
    "    # Combine all rows into a single matrix\n",
    "    A_3 = np.vstack(rows)\n",
    "    print(A_3)\n",
    "\n",
    "    # Combine rows into a single matrix\n",
    "    # define the property of dervied outcome predictor\n",
    "    def K_ac_compute(a,c):\n",
    "        K_ac=np.zeros((3,2))\n",
    "        l_ac=np.zeros((3,1))\n",
    "        K_ac[0:]=[-1,-1]\n",
    "        K_ac[1:]=[(1-TP[c,a,1]), TP[c,a,0]]\n",
    "        K_ac[2:]=[TP[c,a,1], (1-TP[c,a,0])]\n",
    "        l_ac[0:]=[-1]\n",
    "        l_ac[1:]=[TP[c,a,0]]\n",
    "        l_ac[2:]=[TP[c,a,1]]\n",
    "        return K_ac,l_ac\n",
    "    num_clients = 50\n",
    "    block_rows = 3\n",
    "    block_cols = 2\n",
    "    # Define the submatrices k_01, k_11, k_02, k_12 as 3x2 matrices\n",
    "    M = np.zeros((300,200))\n",
    "    l = np.zeros((300, 1))\n",
    "    \n",
    "    # Construct the matrices for all clients\n",
    "    for c in range(num_clients):\n",
    "        for a in range(2):\n",
    "            # Compute submatrices for client c and attribute a\n",
    "            K_ac, l_ac = K_ac_compute(a, c)\n",
    "            \n",
    "            # Calculate starting positions for placing K_ac in M\n",
    "            start_row = (2 * c + a) * block_rows\n",
    "            start_col = (2 * c + a) * block_cols\n",
    "            \n",
    "            # Place K_ac and l_ac in the appropriate block of M and l\n",
    "            M[start_row:start_row + block_rows, start_col:start_col + block_cols] = K_ac\n",
    "            l[start_row:start_row + block_rows] = l_ac\n",
    "    \n",
    "    # Verify the dimensions of the resulting matrix and vector\n",
    "    print(\"Shape of matrix M:\", M.shape)\n",
    "    print(\"Shape of vector l:\", l.shape)\n",
    "    # print(np.shape(A_1),np.shape(A_2),np.shape(A_3),np.shape(M))\n",
    "    # combine the constraints\n",
    "    print(np.shape(A_1),np.shape(A_2),np.shape(A_3),np.shape(M))\n",
    "    A=np.vstack((A_1,A_2,A_3, -A_1, -A_2, -A_3,M))\n",
    "    # print(A)\n",
    "    b_global=e_0*np.ones((2,1))\n",
    "    b_local=e_c*np.ones((100,1))\n",
    "    # print(b_local)\n",
    "    b=np.vstack((b_global,b_local,b_global,b_local,l))\n",
    "    # print(b)\n",
    "    res = linprog(C, A_ub=A, b_ub=b)\n",
    "    x=res.x\n",
    "    x=np.reshape(x,(50,2,2))\n",
    "    return x\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LP_EOp(e_0,e_c):\n",
    "# define the objective function\n",
    "    C=[]\n",
    "    for c in range(50):\n",
    "        for a in range(2):\n",
    "            for y in range(2):\n",
    "                C.append(-S[c,a,y])\n",
    "    #define the global fairness constraints\n",
    "    N=2\n",
    "    K=2\n",
    "    A_2=[]\n",
    "    \n",
    "    for c in range(50):\n",
    "        for a in range(2):\n",
    "            for y in range(2):\n",
    "                if c==c and a==0 and y==1:\n",
    "                    A_2.append(-S[c,a,y]/alpha_a_y[a,y])\n",
    "                elif c==c and a==1 and y==1:\n",
    "                    A_2.append(S[c,a,y]/alpha_a_y[a,y])\n",
    "                else:\n",
    "                    A_2.append(0)\n",
    "    # define local fairness constraints\n",
    "     # Identity matrix of size 50x50, where each row is a basis vector\n",
    "    A_2=np.reshape(A_2,(1,200))\n",
    "    # print(np.shape(A_1),np.shape(A_2))\n",
    "    # To access e_i, you can use basis_vectors[i], e.g., e_0 is basis_vectors[0]\n",
    "    \n",
    "    # Define zero vector in R^50\n",
    "    zero_vec = np.zeros((2,4))\n",
    "    I_vector =[[0,0],[1,0]]\n",
    "    I_vector=np.array(I_vector)\n",
    "    basis_vectors = np.hstack([I_vector, -I_vector])\n",
    "    \n",
    "    # Construct the matrix\n",
    "    # First row: [e_0, e_1, 0, 0]\n",
    "    rows = []\n",
    "\n",
    "# Construct 50 rows dynamically\n",
    "    for i in range(50):\n",
    "        # Initialize the blocks for this row\n",
    "        row_blocks = []\n",
    "        \n",
    "        for j in range(50):\n",
    "            if i == j:  # Diagonal pattern with identity matrices\n",
    "                row_blocks.append(basis_vectors)\n",
    "            else:  # All other positions are zero matrices\n",
    "                row_blocks.append(zero_vec)\n",
    "        \n",
    "        # Horizontally stack the blocks for the current row\n",
    "        row = np.hstack(row_blocks)\n",
    "        rows.append(row)\n",
    "    \n",
    "    # Combine all rows into a single matrix\n",
    "    A_3 = np.vstack(rows)\n",
    "    print(A_3)\n",
    "\n",
    "    # Combine rows into a single matrix\n",
    "    # define the property of dervied outcome predictor\n",
    "    def K_ac_compute(a,c):\n",
    "        K_ac=np.zeros((3,2))\n",
    "        l_ac=np.zeros((3,1))\n",
    "        K_ac[0:]=[-1,-1]\n",
    "        K_ac[1:]=[(1-TP[c,a,1]), TP[c,a,0]]\n",
    "        K_ac[2:]=[TP[c,a,1], (1-TP[c,a,0])]\n",
    "        l_ac[0:]=[-1]\n",
    "        l_ac[1:]=[TP[c,a,0]]\n",
    "        l_ac[2:]=[TP[c,a,1]]\n",
    "        return K_ac,l_ac\n",
    "    num_clients = 50\n",
    "    block_rows = 3\n",
    "    block_cols = 2\n",
    "    # Define the submatrices k_01, k_11, k_02, k_12 as 3x2 matrices\n",
    "    M = np.zeros((300,200))\n",
    "    l = np.zeros((300, 1))\n",
    "    \n",
    "    # Construct the matrices for all clients\n",
    "    for c in range(num_clients):\n",
    "        for a in range(2):\n",
    "            # Compute submatrices for client c and attribute a\n",
    "            K_ac, l_ac = K_ac_compute(a, c)\n",
    "            \n",
    "            # Calculate starting positions for placing K_ac in M\n",
    "            start_row = (2 * c + a) * block_rows\n",
    "            start_col = (2 * c + a) * block_cols\n",
    "            \n",
    "            # Place K_ac and l_ac in the appropriate block of M and l\n",
    "            M[start_row:start_row + block_rows, start_col:start_col + block_cols] = K_ac\n",
    "            l[start_row:start_row + block_rows] = l_ac\n",
    "    \n",
    "    # Verify the dimensions of the resulting matrix and vector\n",
    "    print(\"Shape of matrix M:\", M.shape)\n",
    "    print(\"Shape of vector l:\", l.shape)\n",
    "    # print(np.shape(A_1),np.shape(A_2),np.shape(A_3),np.shape(M))\n",
    "    # combine the constraints\n",
    "    A=np.vstack((A_2,A_3, -A_2, -A_3,M))\n",
    "    # print(A)\n",
    "    b_global=e_0*np.ones((1,1))\n",
    "    b_local=e_c*np.ones((100,1))\n",
    "    # print(b_local)\n",
    "    b=np.vstack((b_global,b_local,b_global,b_local,l))\n",
    "    # print(b)\n",
    "    res = linprog(C, A_ub=A, b_ub=b)\n",
    "    x=res.x\n",
    "    x=np.reshape(x,(50,2,2))\n",
    "    x=np.array(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beta=np.zeros((50,2,3))\n",
    "# for a in range(2):\n",
    "#         for c in range(50):\n",
    "#             A=np.array([[1,1,1],[TP[c,a,0],1,0],[TP[c,a,1],0,1]])\n",
    "#             b=np.array([1,x[c,a,0],x[c,a,1]])\n",
    "#             beta_ac=np.linalg.solve(A,b)\n",
    "#             beta[c,a,:]=beta_ac\n",
    "\n",
    "def compute_tilde_Y(c,a, Y_hat, y_values, beta):\n",
    "    \"\"\"\n",
    "    Compute \\widetilde{Y}_{\\boldsymbol{\\beta}_{ac}}(x,a,c) based on given probabilities.\n",
    "\n",
    "    Parameters:\n",
    "    - beta_ac: Dictionary with keys 'beta_0' and 'beta_y' for probabilities.\n",
    "    - Y_hat: The predicted value \\hat{Y}(x,a,c).\n",
    "    - y_values: List or array of possible y values in \\mathcal{Y}.\n",
    "\n",
    "    Returns:\n",
    "    - tilde_Y: The computed value of \\widetilde{Y}.\n",
    "    \"\"\"\n",
    "    # Extract probabilities\n",
    "    beta_0 = beta[c, a, 0]  # Probability for Y_hat\n",
    "    beta_y = beta[c, a, 1:] \n",
    "    # Probabilities for other y in \\mathcal{Y}\n",
    "    \n",
    "    # Normalize probabilities\n",
    "    \n",
    "    # Generate a random number\n",
    "    rand_val = np.random.rand()\n",
    "    \n",
    "    # Determine the output based on random value\n",
    "    if rand_val < beta_0:\n",
    "        return Y_hat\n",
    "    else:\n",
    "        cumulative_prob = beta_0\n",
    "        for y in y_values:\n",
    "            cumulative_prob += beta_y[y]\n",
    "            if rand_val < cumulative_prob:\n",
    "                return y\n",
    "# # y_tilde_list = [[] for _ in range(50)] \n",
    "# # Example usage\n",
    "# # for c, state in enumerate(states):\n",
    "# #     client_features = test_features[state]\n",
    "# #     client_sensitive = test_groups[state]\n",
    "# #     y_pred=global_model.predict(test_features[state])\n",
    "# #     y_pred=np.where(y_pred<0.5,0,1)\n",
    "# #     for i in range (len(y_pred)):\n",
    "# #         a=int(client_sensitive[i])\n",
    "# #         y_hat=int(y_pred[i])\n",
    "# #         y_tilde=compute_tilde_Y(c,a,y_hat,[0,1],beta)\n",
    "# #         y_tilde=int(y_tilde)\n",
    "# #         y_tilde_list[c].append(y_tilde)\n",
    "# # print(y_tilde_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local_post_EO=[]\n",
    "# for c,state in enumerate(states):\n",
    "#     y_post=y_tilde_list[c]\n",
    "#     y_post=np.reshape(y_post,(-1,))\n",
    "#     y_true=test_labels[state]\n",
    "#     y_group=test_groups[state]\n",
    "#     dis=compute_equal_opp(y_true,y_post,y_group)\n",
    "#     local_post_EO.append(dis)\n",
    "# print('local post EOp',local_post_EO)\n",
    "# y_tilde_list = np.concatenate(y_tilde_list)  \n",
    "\n",
    "# post_EO=compute_equal_opp(all_test_labels,y_tilde_list,all_test_groups)\n",
    "# print('global EOp', post_EO)\n",
    "# #compute accuracy\n",
    "# count=np.where(y_tilde_list==all_test_labels,1,0)\n",
    "# accuracy=np.sum(count)/len(count)\n",
    "# print('accuracy',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_EOd(g,l):\n",
    "    x=LP_EO(g,l)\n",
    "    beta=np.zeros((50,2,3))\n",
    "    for a in range(2):\n",
    "            for c in range(50):\n",
    "                A=np.array([[1,1,1],[TP[c,a,0],1,0],[TP[c,a,1],0,1]])\n",
    "                b=np.array([1,x[c,a,0],x[c,a,1]])\n",
    "                beta_ac=np.linalg.solve(A,b)\n",
    "                beta[c,a,:]=beta_ac\n",
    "    y_tilde_list = [[] for _ in range(50)] \n",
    "# Example usage\n",
    "    for c, state in enumerate(states):\n",
    "        client_features = test_features[state]\n",
    "        client_sensitive = test_groups[state]\n",
    "        y_pred=global_model.predict(test_features[state])\n",
    "        y_pred=np.where(y_pred<0.5,0,1)\n",
    "        for i in range (len(y_pred)):\n",
    "            a=int(client_sensitive[i])\n",
    "            y_hat=int(y_pred[i])\n",
    "            y_tilde=compute_tilde_Y(c,a,y_hat,[0,1],beta)\n",
    "            y_tilde=int(y_tilde)\n",
    "            y_tilde_list[c].append(y_tilde)\n",
    "    local_post_EO=[]\n",
    "    for c,state in enumerate(states):\n",
    "        y_post=y_tilde_list[c]\n",
    "        y_post=np.reshape(y_post,(-1,))\n",
    "        y_true=test_labels[state]\n",
    "        y_group=test_groups[state]\n",
    "        dis=compute_equal_odd(y_true,y_post,y_group)\n",
    "        local_post_EO.append(dis)\n",
    "    print('local post EO',local_post_EO)\n",
    "    local_EO_avg=np.mean(local_post_EO)\n",
    "    print('local post EO average',local_EO_avg)\n",
    "    y_tilde_list = np.concatenate(y_tilde_list)  \n",
    "\n",
    "    post_EO=compute_equal_odd(all_test_labels,y_tilde_list,all_test_groups)\n",
    "    print('global EO', post_EO)\n",
    "    #compute accuracy\n",
    "    count=np.where(y_tilde_list==all_test_labels,1,0)\n",
    "    avg_accuracy=np.sum(count)/len(count)\n",
    "    print('accuracy',accuracy)\n",
    "    return local_EO_avg,post_EO,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_EOp(g,l):\n",
    "    x=LP_EO(g,l)\n",
    "    beta=np.zeros((50,2,3))\n",
    "    for a in range(2):\n",
    "            for c in range(50):\n",
    "                A=np.array([[1,1,1],[TP[c,a,0],1,0],[TP[c,a,1],0,1]])\n",
    "                b=np.array([1,x[c,a,0],x[c,a,1]])\n",
    "                beta_ac=np.linalg.solve(A,b)\n",
    "                beta[c,a,:]=beta_ac\n",
    "    y_tilde_list = [[] for _ in range(50)] \n",
    "# Example usage\n",
    "    for c, state in enumerate(states):\n",
    "        client_features = test_features[state]\n",
    "        client_sensitive = test_groups[state]\n",
    "        y_pred=global_model.predict(test_features[state],verbose=0)\n",
    "        y_pred=np.where(y_pred<0.5,0,1)\n",
    "        for i in range (len(y_pred)):\n",
    "            a=int(client_sensitive[i])\n",
    "            y_hat=int(y_pred[i])\n",
    "            y_tilde=compute_tilde_Y(c,a,y_hat,[0,1],beta)\n",
    "            y_tilde=int(y_tilde)\n",
    "            y_tilde_list[c].append(y_tilde)\n",
    "    local_post_EO=[]\n",
    "    for c,state in enumerate(states):\n",
    "        y_post=y_tilde_list[c]\n",
    "        y_post=np.reshape(y_post,(-1,))\n",
    "        y_true=test_labels[state]\n",
    "        y_group=test_groups[state]\n",
    "        dis=compute_equal_opp(y_true,y_post,y_group)\n",
    "        local_post_EO.append(dis)\n",
    "    print('local post EOp',local_post_EO)\n",
    "    local_EO_avg=np.mean(local_post_EO)\n",
    "    print('local post EOp average',local_EO_avg)\n",
    "    y_tilde_list = np.concatenate(y_tilde_list)  \n",
    "\n",
    "    post_EO=compute_equal_opp(all_test_labels,y_tilde_list,all_test_groups)\n",
    "    print('global EOp', post_EO)\n",
    "    #compute accuracy\n",
    "    count=np.where(y_tilde_list==all_test_labels,1,0)\n",
    "    avg_accuracy=np.sum(count)/len(count)\n",
    "    print('accuracy',avg_accuracy)\n",
    "    return local_EO_avg,post_EO,avg_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_map=[]\n",
    "# local_map=[]\n",
    "# global_map=[]\n",
    "# for l in [0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1]:\n",
    "#     for g in [1]:\n",
    "#         acc_list=[]\n",
    "#         local_list=[]\n",
    "#         global_list=[]\n",
    "#         for _ in range (3):\n",
    "#             local_SP,post_SP,acc=run_EOp(g,l)   \n",
    "#             print('local SP',local_SP)\n",
    "#             print('global SP',post_SP)\n",
    "#             print('global acc',acc)\n",
    "#             acc_list.append(acc)\n",
    "#             local_list.append(local_SP)\n",
    "#             global_list.append(post_SP)\n",
    "#         acc_average_5_runs=np.mean(acc_list)\n",
    "#         local_average_5_runs=np.mean(local_list)\n",
    "#         global_average_5_runs=np.mean(global_list)\n",
    "#         acc_map.append(acc_average_5_runs)\n",
    "#         local_map.append(local_average_5_runs)\n",
    "#         global_map.append(global_average_5_runs)\n",
    "# print(acc_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'acc_map' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43macc_map\u001b[49m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(local_map)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(global_map)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'acc_map' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "print(acc_map)\n",
    "print(local_map)\n",
    "print(global_map)\n",
    "print('acc_map')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.76383239 0.76593147 0.76621629 0.76648628 0.76649073 0.76658419]\n",
      " [0.76492866 0.76948877 0.7728295  0.773322   0.77332645 0.773322  ]\n",
      " [0.76516156 0.76995903 0.77401922 0.77680068 0.77809721 0.77909854]\n",
      " [0.7648174  0.7698359  0.77389609 0.77683628 0.77844879 0.77927359]\n",
      " [0.76506069 0.7698448  0.77406224 0.77665975 0.77822924 0.77927804]\n",
      " [0.76474175 0.76995013 0.77405334 0.77681997 0.77829896 0.77935369]]\n",
      "[[0.0380011  0.04041887 0.04248088 0.04616133 0.04811361 0.05019274]\n",
      " [0.04790597 0.04749832 0.04004022 0.03971188 0.04086205 0.04286356]\n",
      " [0.0516552  0.05409904 0.05697958 0.05413472 0.05343504 0.05243372]\n",
      " [0.05030934 0.05122166 0.05307068 0.05607252 0.05349692 0.05294216]\n",
      " [0.04904623 0.05671942 0.05522323 0.05600677 0.05397283 0.0559164 ]\n",
      " [0.05124003 0.05300967 0.05571926 0.05706133 0.05404726 0.05083131]]\n",
      "[[0.00982592 0.00943227 0.01003538 0.01018875 0.01163716 0.0109395 ]\n",
      " [0.01881784 0.0185595  0.01925071 0.01957294 0.02009344 0.01957903]\n",
      " [0.02060941 0.02784697 0.03036172 0.02931326 0.02873896 0.02830064]\n",
      " [0.02050739 0.0277767  0.03322657 0.03590415 0.0347949  0.03120884]\n",
      " [0.02079239 0.02763122 0.03541327 0.03528169 0.03581277 0.03096931]\n",
      " [0.02100261 0.02701776 0.03377189 0.0348598  0.03471797 0.0302295 ]]\n"
     ]
    }
   ],
   "source": [
    "acc_map=np.transpose(acc_map)\n",
    "local_map=np.transpose(local_map)\n",
    "global_map=np.transpose(global_map)\n",
    "print(acc_map)\n",
    "print(local_map)\n",
    "print(global_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ± Error: 5.9 ± 2.202297749494614\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "def compute_confidence_interval(data, confidence=0.95):\n",
    "    \"\"\"\n",
    "    Compute the confidence interval for a given list of numbers.\n",
    "\n",
    "    Parameters:\n",
    "    data (list or array-like): List of numbers.\n",
    "    confidence (float): Confidence level for the interval.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Mean and the margin of error for the confidence interval.\n",
    "    \"\"\"\n",
    "    data = np.array(data)\n",
    "    n = len(data)\n",
    "    mean = np.mean(data)\n",
    "    std_err = stats.sem(data)  # Standard error of the mean\n",
    "    margin_of_error = std_err * stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "\n",
    "    return mean, margin_of_error\n",
    "\n",
    "# Example usage:\n",
    "data = [1.2, 2.3, 3.1, 4.5, 5.9, 6.7, 7.4, 8.1, 9.3, 10.5]\n",
    "mean, margin_of_error = compute_confidence_interval(data)\n",
    "print(f\"Mean ± Error: {mean} ± {margin_of_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0. -1. ...  0.  0.  0.]\n",
      " [ 0.  1. -0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0. -1. -0.]\n",
      " [ 0.  0.  0. ...  1. -0. -1.]]\n",
      "Shape of matrix M: (300, 200)\n",
      "Shape of vector l: (300, 1)\n",
      "(1, 200) (1, 200) (100, 200) (300, 200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3730862/3000681083.py:19: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_hat=int(y_pred[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local post EOp [0.04857705471423879, 0.026836158192090398, 0.057354627613125875, 0.0030054757297542367, 0.04485968984726235, 0.050776030424504015, 0.07584752909428238, 0.020566459043365848, 0.03371819664050357, 0.005236950549450503, 0.07655502392344499, 0.021699346405228748, 0.01734431771297762, 0.00862943995690213, 0.1450268093075759, 0.008769948810599226, 0.010164037359704892, 0.0680482750213337, 0.004084967320261423, 0.022064570027218622, 0.10453155407283848, 0.07382946883645419, 0.07080159381225831, 0.07020344520344524, 0.09329565979363008, 0.20443779606083273, 0.04435070117432449, 0.06410106616036221, 0.07763157894736844, 0.03779024899211597, 0.06266749123891985, 0.07464315259959037, 0.020002515591923564, 0.033333333333333326, 0.024065383789970696, 0.014722222222222192, 0.01543762432509238, 0.010604622575545841, 0.20751264664729308, 0.009026410258826167, 0.07446808510638303, 0.015032377428307153, 0.006237798394415239, 0.518796992481203, 0.18997668997669, 0.08170600508574044, 0.04964409118103125, 0.1859320557491289, 0.020049504950495067, 0.5892857142857143]\n",
      "local post EOp average 0.07586565475938561\n",
      "global EOp 0.031179148676607205\n",
      "accuracy 0.780669508949631\n",
      "local SP 0.07586565475938561\n",
      "global SP 0.031179148676607205\n",
      "global acc 0.780669508949631\n",
      "[[ 1.  0. -1. ...  0.  0.  0.]\n",
      " [ 0.  1. -0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0. -1. -0.]\n",
      " [ 0.  0.  0. ...  1. -0. -1.]]\n",
      "Shape of matrix M: (300, 200)\n",
      "Shape of vector l: (300, 1)\n",
      "(1, 200) (1, 200) (100, 200) (300, 200)\n",
      "local post EOp [0.04857705471423879, 0.026836158192090398, 0.057354627613125875, 0.0030054757297542367, 0.04485968984726235, 0.050776030424504015, 0.07584752909428238, 0.020566459043365848, 0.03371819664050357, 0.005236950549450503, 0.07655502392344499, 0.021699346405228748, 0.01734431771297762, 0.00862943995690213, 0.1450268093075759, 0.008769948810599226, 0.010164037359704892, 0.0680482750213337, 0.004084967320261423, 0.022064570027218622, 0.10453155407283848, 0.07382946883645419, 0.07080159381225831, 0.07020344520344524, 0.09329565979363008, 0.20443779606083273, 0.04435070117432449, 0.06410106616036221, 0.07763157894736844, 0.03779024899211597, 0.06266749123891985, 0.07464315259959037, 0.020002515591923564, 0.033333333333333326, 0.024065383789970696, 0.014722222222222192, 0.01543762432509238, 0.010604622575545841, 0.20751264664729308, 0.009026410258826167, 0.07446808510638303, 0.015032377428307153, 0.006237798394415239, 0.518796992481203, 0.18997668997669, 0.08170600508574044, 0.04964409118103125, 0.1859320557491289, 0.020049504950495067, 0.5892857142857143]\n",
      "local post EOp average 0.07586565475938561\n",
      "global EOp 0.031179148676607205\n",
      "accuracy 0.780669508949631\n",
      "local SP 0.07586565475938561\n",
      "global SP 0.031179148676607205\n",
      "global acc 0.780669508949631\n",
      "[[ 1.  0. -1. ...  0.  0.  0.]\n",
      " [ 0.  1. -0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0. -1. -0.]\n",
      " [ 0.  0.  0. ...  1. -0. -1.]]\n",
      "Shape of matrix M: (300, 200)\n",
      "Shape of vector l: (300, 1)\n",
      "(1, 200) (1, 200) (100, 200) (300, 200)\n",
      "local post EOp [0.04857705471423879, 0.026836158192090398, 0.057354627613125875, 0.0030054757297542367, 0.04485968984726235, 0.050776030424504015, 0.07584752909428238, 0.020566459043365848, 0.03371819664050357, 0.005236950549450503, 0.07655502392344499, 0.021699346405228748, 0.01734431771297762, 0.00862943995690213, 0.1450268093075759, 0.008769948810599226, 0.010164037359704892, 0.0680482750213337, 0.004084967320261423, 0.022064570027218622, 0.10453155407283848, 0.07382946883645419, 0.07080159381225831, 0.07020344520344524, 0.09329565979363008, 0.20443779606083273, 0.04435070117432449, 0.06410106616036221, 0.07763157894736844, 0.03779024899211597, 0.06266749123891985, 0.07464315259959037, 0.020002515591923564, 0.033333333333333326, 0.024065383789970696, 0.014722222222222192, 0.01543762432509238, 0.010604622575545841, 0.20751264664729308, 0.009026410258826167, 0.07446808510638303, 0.015032377428307153, 0.006237798394415239, 0.518796992481203, 0.18997668997669, 0.08170600508574044, 0.04964409118103125, 0.1859320557491289, 0.020049504950495067, 0.5892857142857143]\n",
      "local post EOp average 0.07586565475938561\n",
      "global EOp 0.031179148676607205\n",
      "accuracy 0.780669508949631\n",
      "local SP 0.07586565475938561\n",
      "global SP 0.031179148676607205\n",
      "global acc 0.780669508949631\n",
      "[[ 1.  0. -1. ...  0.  0.  0.]\n",
      " [ 0.  1. -0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0. -1. -0.]\n",
      " [ 0.  0.  0. ...  1. -0. -1.]]\n",
      "Shape of matrix M: (300, 200)\n",
      "Shape of vector l: (300, 1)\n",
      "(1, 200) (1, 200) (100, 200) (300, 200)\n",
      "local post EOp [0.04857705471423879, 0.026836158192090398, 0.057354627613125875, 0.0030054757297542367, 0.04485968984726235, 0.050776030424504015, 0.07584752909428238, 0.020566459043365848, 0.03371819664050357, 0.005236950549450503, 0.07655502392344499, 0.021699346405228748, 0.01734431771297762, 0.00862943995690213, 0.1450268093075759, 0.008769948810599226, 0.010164037359704892, 0.0680482750213337, 0.004084967320261423, 0.022064570027218622, 0.10453155407283848, 0.07382946883645419, 0.07080159381225831, 0.07020344520344524, 0.09329565979363008, 0.20443779606083273, 0.04435070117432449, 0.06410106616036221, 0.07763157894736844, 0.03779024899211597, 0.06266749123891985, 0.07464315259959037, 0.020002515591923564, 0.033333333333333326, 0.024065383789970696, 0.014722222222222192, 0.01543762432509238, 0.010604622575545841, 0.20751264664729308, 0.009026410258826167, 0.07446808510638303, 0.015032377428307153, 0.006237798394415239, 0.518796992481203, 0.18997668997669, 0.08170600508574044, 0.04964409118103125, 0.1859320557491289, 0.020049504950495067, 0.5892857142857143]\n",
      "local post EOp average 0.07586565475938561\n",
      "global EOp 0.031179148676607205\n",
      "accuracy 0.780669508949631\n",
      "local SP 0.07586565475938561\n",
      "global SP 0.031179148676607205\n",
      "global acc 0.780669508949631\n",
      "[[ 1.  0. -1. ...  0.  0.  0.]\n",
      " [ 0.  1. -0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0. -1. -0.]\n",
      " [ 0.  0.  0. ...  1. -0. -1.]]\n",
      "Shape of matrix M: (300, 200)\n",
      "Shape of vector l: (300, 1)\n",
      "(1, 200) (1, 200) (100, 200) (300, 200)\n",
      "local post EOp [0.04857705471423879, 0.026836158192090398, 0.057354627613125875, 0.0030054757297542367, 0.04485968984726235, 0.050776030424504015, 0.07584752909428238, 0.020566459043365848, 0.03371819664050357, 0.005236950549450503, 0.07655502392344499, 0.021699346405228748, 0.01734431771297762, 0.00862943995690213, 0.1450268093075759, 0.008769948810599226, 0.010164037359704892, 0.0680482750213337, 0.004084967320261423, 0.022064570027218622, 0.10453155407283848, 0.07382946883645419, 0.07080159381225831, 0.07020344520344524, 0.09329565979363008, 0.20443779606083273, 0.04435070117432449, 0.06410106616036221, 0.07763157894736844, 0.03779024899211597, 0.06266749123891985, 0.07464315259959037, 0.020002515591923564, 0.033333333333333326, 0.024065383789970696, 0.014722222222222192, 0.01543762432509238, 0.010604622575545841, 0.20751264664729308, 0.009026410258826167, 0.07446808510638303, 0.015032377428307153, 0.006237798394415239, 0.518796992481203, 0.18997668997669, 0.08170600508574044, 0.04964409118103125, 0.1859320557491289, 0.020049504950495067, 0.5892857142857143]\n",
      "local post EOp average 0.07586565475938561\n",
      "global EOp 0.031179148676607205\n",
      "accuracy 0.780669508949631\n",
      "local SP 0.07586565475938561\n",
      "global SP 0.031179148676607205\n",
      "global acc 0.780669508949631\n",
      "acc 0.780669508949631 0.0\n",
      "local 0.07586565475938561 0.0\n",
      "global 0.031179148676607205 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for l in [1]:\n",
    "    for g in [1]:\n",
    "        acc_list=[]\n",
    "        local_list=[]\n",
    "        global_list=[]\n",
    "        for _ in range (5):\n",
    "            local_SP,post_SP,acc=run_EOp(g,l)   \n",
    "            print('local SP',local_SP)\n",
    "            print('global SP',post_SP)\n",
    "            print('global acc',acc)\n",
    "            acc_list.append(acc)\n",
    "            local_list.append(local_SP)\n",
    "            global_list.append(post_SP)\n",
    "        acc_mean, acc_error = compute_confidence_interval(acc_list)\n",
    "        local_mean, local_error = compute_confidence_interval(local_list)\n",
    "        global_mean, global_error = compute_confidence_interval(global_list)\n",
    "        print('acc',acc_mean,acc_error)\n",
    "        print('local',local_mean,local_error)\n",
    "        print('global',global_mean,global_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
